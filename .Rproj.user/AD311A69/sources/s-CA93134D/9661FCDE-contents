library(wavethresh)
library(ashr)
library(mixsqp)



'%!in%' <- function(x,y)!('%in%'(x,y))
##### IBSS with mixture per level ------------

#input

#Y functionnal phenotype, matrix of size N by size Ji, if Ji not of size J^2, automatic handling
#pos genomic position for each observation in Y, if missing suppose that the observation are evenly spaced
#X genotype matrix, matrix of size n by p in the current version all the elements have to be 0 or 1
#L the number of effect to fit (if not specified =2)
#my_col_pos color of the points for the alpha plot (for simulation)

#output
#pip Posterior inclusion probability,
#cs  Credible sets
#fitted_baseline, TO BE Implemented, vector of size 2^J, baseline in the original space, expected function when no effect.
#fitted_wc, list of length l, each element is a matrix of size 2^J x p containning the fitted wavelet coefficient for each effect.
#                            the column are the variable effect in the wavelet space, first element of the column correspond to the C coefficient
#                             the second correspond to the d coefficient (1,1), the third to the d coefficient (1,2), 4th (2,2), 5th (2,3) and so on
#fitted_func, list of length l, each element is a vector of length 2^J representing the fitted function for each effect (i.e. fitted_wc[[l]]%*%alpha[[l]] in the original space)
#ind_pred individual prediction of the model
#alpha
#alpha_history
#outing_grid, grid of size 2^J used to perform the wavelet transform. This correspond of the x axis of the fitted functions.
#est_pi0 list of the proportion of wavelet coefficients not affected by the selected covariate



IBSS_per_level  <- function(Y,X, L=2,  plot_out =TRUE, my_col_pos, pos,verbose =TRUE, maxit=100, tol = 10^(-6))
{
  if( missing(my_col_pos))
  {
    my_col_pos <- rep( "black", dim(X)[2])
  }

  #To solve some strange issue related to argument calling when using simu_full() function,
  #I put this  function here
  #Itshould be outside of IBSS_MS

  if (missing(pos))
  {
    pos <- 1:dim(Y)[2]
  }

  #control0 <- list(verbose    = FALSE,
  #                 eps        = 1e-6,
  #                 numiter.em = 20)
  #control  <- modifyList(control0,control,keep.null = TRUE)

  ###########
  #Description
  #function to obtain the fitted effect from a Single effect Wavelet regression
  #Depend on more parameters than the one currently in place, these parameters stay fix during a SuSIe.



  #Interpollation procedure from Kovac and Silveramnn 2000, code from wavethresh package Guy Nason
  #Y a matrix of size  N x Ji where (Ji is the number of observed point by )

  interpolKS <- function(Y )
  {

    bp<- (pos- min(pos))/(max(pos)-min(pos))
    interpolation <-  function (y)
    {
      wavethresh::makegrid(t=bp,y=y, gridn = 2^(floor(log(length(pos)-1,2)) + 1)   )$gridy
    }
    inter_Y  <- apply( Y,1,  interpolation)
    out <- t(inter_Y)
  }


  #reshapping of the data
  if ( !(length(pos)==dim(Y)[2])) #miss matching positions and number of observations
  {
    stop("Error: number of position provided different from number of column of Y")
  }
  orignal_Y <-Y

  is.wholenumber <- function(x, tol = .Machine$double.eps^0.5)  abs(x - round(x)) < tol


  if(!is.wholenumber(log2(dim(Y)[2])) | !(sum( duplicated(diff( pos)))== (length(pos) -2)) ) #check wether dim(Y) not eqaul to 2^J or if the data are unevenly spaced
  {

    Y <- interpolKS(Y)
    bp<- (pos- min(pos))/(max(pos)-min(pos))
    outing_grid <- max(pos)*wavethresh::makegrid(t=bp,y=rep(0, length(pos)), gridn = 2^(floor(log(length(pos)-1,2)) + 1)    )$gridt
    print( "Response matrix dimensions not equal to nx 2^J, J integer \n interpolation procedure used")
  }  else{

    outing_grid <- 1:dim(Y)[2]
  }

  ### utils -----


  #pi_k_s list of length s where each element is a vector of mixture weight

  #sd_k_s list of length s where each element is a vector of mixture sd

  ### to speed up
  log_BF_mix_per_scale <- function(pi_k_s, sd_k_s , reg_coef_j, sd_coef_j)
  {

    tt <-  rep(0, length(reg_coef_j))
    for (s in 1:length(indx_lst))
    {
      for( k in 1:length(pi_k_s[[s]]))
      {
        #sum over the K component for scale s

        tt[indx_lst[[s]] ] <- tt[indx_lst[[s]] ]+ pi_k_s[[s]][k]*dnorm(
          reg_coef_j[indx_lst[[s]] ],
          sd= sqrt(sd_k_s[[s]][k]^2 +  (sd_coef_j[indx_lst[[s]] ])^2), log=TRUE
        )

      }
      # print(tt)
    }

    out <- sum ( tt  -   dnorm(  reg_coef_j,sd= sd_coef_j, log=TRUE) )
    return(out)
  }

  e_log_BF_mix_scale <- function(j)
  {
    return(
      log_BF_mix_per_scale(pi_k_s=pi_k_s,
                           sd_k_s= sd_k_s,
                           reg_coef_j=Bhat[j,] ,
                           sd_coef_j= Shat[j,]
      )
    )
  }

  ##Return a matrix L with j*t rows, where each row corresponds to a wavelet coefficient
  # row 1 corresponds to wave coeff for X[,1], row t+1 corresponds to wave coeff for X[, 2] etc
  #columns  L[j,k] is the log value of the kth mixture component density at the jth data point (mixsqp doc)
  #L argument as in the mix sq
  get_L_mixsq_one_scale <- function(G_prior, Bhat, Shat,s)
  {
    m <-  (G_prior[[s]])


    sdmat <-sqrt(outer(c(Shat[,indx_lst[[s]]]^2),m$fitted_g$sd^2,"+"))
    L = (dnorm(outer(c(Bhat[,indx_lst[[s]]]),m$fitted_g$mean,FUN="-")/sdmat,log=TRUE) -log(sdmat ))


    return(L)
  }


  EM_pi_mix_accros_scale <- function(G_prior,Bhat, Shat){

    #static parameters
    get_Ls <- function(s)
    {
      get_L_mixsq_one_scale(G_prior, Bhat, Shat,s)
    }

    L_mixsq_scale <- lapply(1:length(indx_lst  ) ,  get_Ls)

    max_step =100
    espsilon =0.0001
    #dynamic parameters
    pi_k_s <- list()
    sd_k_s <- list()

    for ( s in 1:length(indx_lst) )
    {

      pi_k_s[[s]] <- G_prior[[s]]$fitted_g$pi
      sd_k_s[[s]] <- G_prior[[s]]$fitted_g$sd
    }

    J <- dim(Bhat)[1]
    oldloglik <-0
    newloglik <-1
    n_wav_coef <- dim(Bhat)[2]
    zeta <- rep(1/J,J)
    k <- 1


    lBF <- do.call(c,lapply(1:J,e_log_BF_mix_scale ))
    if( prod(is.finite(lBF) )==0) #avoid extrem overflow problem when little noise is present
    {
      lBF <-  ifelse(lBF==Inf,max(1000, 10*max(lBF[-which(lBF==Inf)])),lBF)
      lBF <-  ifelse(lBF== -Inf,max(-1000, -10*max(lBF[-which(lBF== -Inf)])),lBF)
    }

    while( k <max_step &  abs(newloglik-oldloglik)>=espsilon)
    {
      ###E step----
      #easier to plug into  a apply function
      #but pi_k, sd_k have to be updated at every loop


      oldloglik <- sum( zeta*exp(lBF - max(lBF ) ))
      zeta <- exp(lBF - max(lBF ) ) /sum( exp(lBF - max(lBF ) ))

      #zeta are the assignement proba/weight afterwards

      ####M step ---




      #setting the weight to fit the wieghted ash problem
      scale_mixsqp <- function(s)
      {
        w <- rep(zeta,length(indx_lst[[s]] ))
        tlength <- dim(L_mixsq_scale[[s]])[2]-1
        return(mixsqp( L_mixsq_scale[[s]] ,
                       w,
                       x0 = c(1, rep(1e-30,  tlength )),
                       log=TRUE ,
                       control = list(
                         eps = 1e-6,
                         numiter.em = 20,
                         verbose=FALSE
                       )
        )$x
        )

      }

      out.mixsqp <- lapply(1:length(indx_lst) , scale_mixsqp)
      tpi_k <- out.mixsqp


      lBF <- do.call(c,lapply(1:J,e_log_BF_mix_scale))
      if( prod(is.finite(lBF) )==0) #avoid extrem overflow problem when little noise is present
      {
        lBF <-  ifelse(lBF==Inf,max(1000, 10*max(lBF[-which(lBF==Inf)])),lBF)
        lBF <-  ifelse(lBF== -Inf,max(-1000, -10*max(lBF[-which(lBF== -Inf)])),lBF)
      }

      newloglik <- sum( zeta*exp(lBF - max(lBF ) ))


      k <- k+1

    }
    out =list (tpi_k=tpi_k,
               lBF =lBF )
    return(out )
  }





  #perform wavelet transform on matrices of size nx2^j
  DWT2 <- function (data, filter.number = 10, family = "DaubLeAsymm")
  {
    if (sum(methods::is(data) == c("numeric", "vector")) == 2) {
      data <- matrix(data, nrow = 1)
    }
    J <- ncol(data)
    n <- nrow(data)
    D <- matrix(NA, nrow = n, ncol = J - 1)
    C <- rep(NA, n)
    for (i in 1:n) {
      temp <- wd(data[i, ], filter.number = filter.number,
                 family = family)
      D[i, ] <- temp$D
      C[i] <- accessC(temp, level = 0)
    }
    output <- list(C = C, D = D, J = log2(J), filter.number = filter.number,
                   family = family)
    class(output) <- "DWT"
    return(output)
  }









  ##Defintion of static parameter ----

  P <- dim(X)[2]  #number of covariates
  N <- dim(X)[1]  #number of individuals
  m <- length(outing_grid)  #number of d wavelet coefficients, assuming dim(Y)[2]= 2^J
  if(m > 1024) #to prevent to analyse to fine grain data, wavetresh do njot support more than lev_res >10
  {
    lev_res <- 10
    print("Number of time points too large, analysis performed on reduced data containning 1024 time points")
  }else{
    lev_res <- which(m/(2^(1:10)) ==1)
  }
  v1 <- rep(1, dim(X)[1])### used in fit_lm to add a column of 1 in the design matrix

  ####### dynamic parameter -------------
  #Intialisation and declaration of the dynamic parameter

  log_BF_row      <- list() #logarithmic Bayes factors row prior
  log_BF_col      <- list() #logarithmic Bayes factors  col prior
  fitted_wc_row   <- list()#fitted coefficient for function specific prior
  fitted_wc_col   <- list()# fitted coef for wavelet coeff  specific prior
  fitted_wc_row2  <- list()#varaince est coeff for function specific prior
  fitted_wc_col2   <- list()#varaince est coeff wit wavelet coeff  specific prior
  alpha_row       <- list()#PiP
  alpha_col       <- list()#PiP
  alpha_row_hist  <- list() # hist PiP
  alpha_col_hist  <- list() # hist PiP
  fitted_func <- list()
  check <- 1 # paramter to check convergence
  for ( l in 1:L) #initialize all the coefficients to zero
  {

    fitted_wc_row[[l]]  <- matrix(0,ncol=m,nrow=P)
    fitted_wc_col[[l]]  <- matrix(0,ncol=m,nrow=P)
    alpha_row[[l]]      <- rep(0,P)
    alpha_col[[l]]      <- rep(0,P)
  }

  Bhat  <- list()
  Shat  <- list()




  ###### #Wavelet transform of the dat  ----------






  W <- DWT2(Y)
  update_D <- W
  Y_f <- cbind( W$D,W$C) #Using a column like phenotype
  lev_res <- log2(dim(Y_f))[2]
  update_Y <-Y_f

  ##### fittting prior ---------


  #### G with s,l specific prior ---------

  print( "fitting prior")


  fit_lm <- function( l,j)
  {


    out <- lm(Y_f[,l]~X[,j])
    return(summary(out)$coefficients[2,1:2])

  }



  ##### fitting the ash priors


  Bhat  <- list()
  Shat  <- list()

  for ( j in 1:(dim(Y)[2] ))
  {
    out <- mapply(fit_lm, j,1:dim(X)[2])
    Bhat[[j]]  <- out[1,]
    Shat[[j]] <- out[2,]
  }

  Bhat <- (do.call(cbind, Bhat))
  Shat <- (do.call(cbind, Shat))

  #fit an ash prior using coefficient in column t in matrices Bhat (reg coeff) and Shat (standard error)

  fit_ash_level <- function(s)
  {
    out <- ash(c(Bhat[,indx_lst[[s]] ]),c(Shat[, indx_lst[[s]] ]),mixcompdist ="normal"
    )
    return(out)
  }




  indx_lst <- list()
  indx_lst[[1]] <- 2^lev_res -1 #coefficient
  for ( s in 1:(lev_res-1))
  {

    indx  <- 2^(lev_res)- (2^((s+1))-1) :(2^s)


    indx_lst[[s+1]] <- indx
  }
  indx_lst[[length(indx_lst)+1]] <- 2^lev_res# C coefficient




  #first log2(Y_f)+1 element of G_prior   are ash prior fitted per level coefficient on var 1
  # element in  (log2(Y_f)+2):  2*( log2(Y_f)+1)   of G_prior   are ash prior fitted per level coefficient on var 2


  G_prior  <-  lapply(1: length(indx_lst)  ,
                      FUN= fit_ash_level )



  #### problem la
  post_ash_level <- function( G_prior ,Bhat,Shat )
  {
    get_t_col_post <- function(t ){

      get_t_s_post <- function(s){
        m <- G_prior [[ s]]

        data <-  set_data(Bhat[t,indx_lst[[s]] ],
                          Shat[t, indx_lst[[s]] ]
        )
        return(postmean(get_fitted_g(m),data))
      }
      return(unlist( lapply( c(log2(dim(Y_f)[2] ): 1,(log2(dim(Y_f)[2] )+1 )), #important to maintain the ordering of the wavethresh package !!!!
                             get_t_s_post ) ))
    }

    out <- lapply( 1:(dim(X)[2]),
                   FUN= get_t_col_post)



    return(do.call(cbind, out))
  }


  post_sd_level <- function( G_prior ,Bhat,Shat )
  {
    get_t_col_post <- function(t ){

      get_t_s_post <- function(s){
        m <- G_prior [[ s]]

        data <-  set_data(Bhat[t,indx_lst[[s]] ],
                          Shat[t, indx_lst[[s]] ]
        )
        return(postsd(get_fitted_g(m),data))
      }
      return(unlist(lapply( c(log2(dim(Y_f)[2] ): 1,(log2(dim(Y_f)[2] )+1 )), #important to maintain the ordering of the wavethresh package !!!!
                            get_t_s_post )))
    }

    out <- lapply( 1:(dim(X)[2]),
                   FUN= get_t_col_post)



    return(do.call(cbind, out))
  }


  ##### Cor start here --------

  get_log_BF <- function( G_prior ,Bhat,Shat )
  {
    get_t_col_post <- function(t ){

      get_t_s_post <- function(s){
        m <- G_prior  [[(t-1)*(log2(dim(Y_f)[2] )+1)+s]]

        data <-  set_data(Bhat[t,indx_lst[[s]] ],
                          Shat[t, indx_lst[[s]] ]
        )
        return(calc_logLR (get_fitted_g(m),data))
      }
      return(sum(unlist(lapply(1:(log2(dim(Y_f)[2] )+1 ),#important to maintain the ordering of the wavethresh package !!!!
                               get_t_s_post ))))
    }

    out <- lapply( 1:(dim(X)[2]),
                   FUN= get_t_col_post)
    return(do.call(c, out))
  }


  pi_k_s <- list()
  sd_k_s <- list()
  pi_prior_list <- list()
  for ( s in 1:length(indx_lst) )
  {

    pi_k_s[[s ]] <- G_prior[[s ]]$fitted_g$pi
    sd_k_s[[s ]] <- G_prior[[s ]]$fitted_g$sd
  }
  for( l in 1:L)
  {
    pi_prior_list[[l]] <- pi_k_s
  }

  #IBSS ash ---------
  if(verbose == TRUE)
  {
    print("starting IBSS")
  }
  h <- 0 #index of history of alpha
  if(L==1){
    h <- h+1
    #l colmun of wavelet response matrix
    #j column of the covariate matrix
    #Fitting the effect variable by variable
    Bhat  <- list()
    Shat  <- list()
    #compute regression coefficient whitun the resiudals

    for ( j in 1:dim(Y)[2])
    {
      out <- mapply(fit_lm, j,1:dim(X)[2])
      Bhat[[j]]  <- out[1,]
      Shat[[j]] <- out[2,]
    }
    Bhat <- (do.call(cbind, Bhat))
    Shat <- (do.call(cbind, Shat))
    t_prior <- G_prior
    pi_k_s <- pi_prior_list[[l]] # restart EM close to previously fitted pi_k_s
    EM_out <- EM_pi_mix_accros_scale(G_prior= t_prior, Bhat,Shat)
    pi_prior_list[[l]] <- EM_out$tpi_k
    log_BF <- EM_out$lBF
    for( s in 1:log2(dim(Y_f)[2] ))
    {
      G_prior[[s ]]$fitted_g$pi <- unlist(pi_prior_list[[l]] [s])
    }
    fitted_wc_col[[l]]   <- t(post_ash_level(G_prior  , Bhat, Shat ))
    fitted_wc_col2[[l]]  <- t(post_sd_level(G_prior  ,Bhat, Shat ))



    alpha_col[[l]] <- exp(log_BF - max(log_BF ) ) /sum( exp(log_BF - max(log_BF ) )) #avoid overflow
  }else{
    while(check >tol & (0.5*h) <maxit)
    {



      for ( l in 1: L)
      {
        h <- h+1
        #l colmun of wavelet response matrix
        #j column of the covariate matrix
        #Fitting the effect variable by variable
        Bhat  <- list()
        Shat  <- list()
        #compute regression coefficient whitun the resiudals

        for ( j in 1:(dim(Y)[2]))
        {
          out <- mapply(fit_lm, j,1:dim(X)[2])
          Bhat[[j]]  <- out[1,]
          Shat[[j]] <- out[2,]
        }
        Bhat <- (do.call(cbind, Bhat))
        Shat <- (do.call(cbind, Shat))
        t_prior <- G_prior
        pi_k_s <- pi_prior_list[[l]] # restart EM close to previously fitted pi_k_s
        EM_out <- EM_pi_mix_accros_scale(G_prior= t_prior, Bhat,Shat)
        pi_prior_list[[l]] <- EM_out$tpi_k
        log_BF <- EM_out$lBF
        for( s in 1:log2(dim(Y_f)[2] ))
        {
          G_prior[[s ]]$fitted_g$pi <- unlist(pi_prior_list[[l]] [s])
        }


        fitted_wc_col[[l]]   <- t(post_ash_level(G_prior  , Bhat, Shat ))
        fitted_wc_col2[[l]]  <- t(post_sd_level(G_prior  ,Bhat, Shat ))




        alpha_col[[l]] <- exp(log_BF - max(log_BF ) ) /sum( exp(log_BF - max(log_BF ) )) #avoid overflow
        if(verbose ==TRUE)
        {
          plot(alpha_col[[l]], main = paste("loop", ceiling(h/L), "effect",l))
        }
        id_L <- (1:L)[ - ( (l%%L)+1) ]#Computing residuals R_{l+1} by removing all the effect except effect l+1
        update_D$D <-  W$D -Reduce("+", lapply  ( id_L, function(l) (X*rep(alpha_col[[l]], rep.int(N,P))) %*% (fitted_wc_col[[l]][,-indx_lst[[length(indx_lst)]]])   ) )
        update_D$C <-  W$C -Reduce("+", lapply  ( id_L, function(l) (X*rep(alpha_col[[l]], rep.int(N,P))) %*% fitted_wc_col[[l]][,indx_lst[[length(indx_lst)]]] ) )
        Y_f  <- cbind(  update_D$D, update_D$C)

        alpha_col_hist[[h]] <- alpha_col[[l]]

      }
      if(ceiling(h/L)>2)#update parameter convergebnce
      {
        check <-0
        for( tt in 0:(L-1))
        {
          check <-  check + var( alpha_col_hist[[h-tt]] -alpha_col_hist[[h-L-tt]])
        }

      }

    }

  }




  ##### Tidding output ----
  temp <- wd(rep(0, dim(Y_f)[2]))
  for ( l in 1:L)
  {


    temp$D <-    (alpha_col[[l]])%*%fitted_wc_col[[l]][,-indx_lst[[length(indx_lst)]]]
    temp$C[length(temp$C)] <- (alpha_col[[l]])%*%fitted_wc_col[[l]][,indx_lst[[length(indx_lst)]]]
    fitted_func[[l]] <- wr(temp)


  }


  ########################
  #Individual prediction -----
  ########################
  ind_fitted_func <- matrix(NA, ncol = m, nrow = N)
  for ( i in 1:N)
  {
    ind_fitted_func[i,]  <- rep(0,dim(Y_f)[2])#fitted_baseline
    for ( l in 1: L)
    {

      temp$D <-    (alpha_col[[l]] *X[i,])%*%fitted_wc_col[[l]][,-indx_lst[[length(indx_lst)]]]
      temp$C[length(temp$C)] <- (alpha_col[[l]] *X[i,]) %*%fitted_wc_col[[l]][,indx_lst[[length(indx_lst)]]]
      ind_fitted_func[i,]  <-  ind_fitted_func[i,]+wr(temp)
    }
  }



  #### Compute CS and PIP
  pip <- list()
  cs <- list()
  for( l in 1:L)
  {

    temp        <- alpha_col[[l]]
    temp_cumsum <- cumsum( temp[order(temp, decreasing =TRUE)])
    max_indx_cs <- min(which( temp_cumsum >0.95))
    cs[[l]]  <- order(temp, decreasing = TRUE)[1:max_indx_cs ]
    pip[[l]] <- rep(1, dim(X)[2])-alpha_col[[l]]
  }
  pip <- 1-  apply( do.call(rbind,pip),2, prod)

  out <- list( #fitted_baseline = fitted_baseline,
    pip             = pip,
    cs              = cs,
    fitted_wc       = fitted_wc_col ,
    fitted_func     = fitted_func,
    ind_pred        = ind_fitted_func,
    alpha           = alpha_col,
    alpha_hist      = alpha_col_hist,
    #elbohist        = elbohist,
    outing_grid     = outing_grid,
    out_pi_k_s      = pi_prior_list,
    out_sd_k        = sd_k_s,
    est_pi0         = lapply(pi_prior_list, function(x){unlist( lapply(x, function(y) y[1])) } )
  )

  return(out)
}

##### IBSS with one ash for everything ------------

#input

#Y functionnal phenotype, matrix of size N by size Ji, if Ji not of size J^2, automatic handling
#pos genomic position for each observation in Y, if missing suppose that the observation are evenly spaced
#X genotype matrix, matrix of size n by p in the current version all the elements have to be 0 or 1
#L the number of effect to fit (if not specified =2)
#my_col_pos color of the points for the alpha plot (for simulation)

#output
#pip Posterior inclusion probability,
#cs  Credible sets
#fitted_baseline, TO BE Implemented, vector of size 2^J, baseline in the original space, expected function when no effect.
#fitted_wc, list of length l, each element is a matrix of size 2^J x p containning the fitted wavelet coefficient for each effect.
#                            the column are the variable effect in the wavelet space, first element of the column correspond to the C coefficient
#                             the second correspond to the d coefficient (1,1), the third to the d coefficient (1,2), 4th (2,2), 5th (2,3) and so on
#fitted_func, list of length l, each element is a vector of length 2^J representing the fitted function for each effect (i.e. fitted_wc[[l]]%*%alpha[[l]] in the original space)
#ind_pred individual prediction of the model
#alpha
#alpha_history
#outing_grid, grid of size 2^J used to perform the wavelet transform. This correspond of the x axis of the fitted functions.


IBSS_ash_vanilla <- function(Y,X, L=2,  plot_out =TRUE, my_col_pos, pos,verbose =TRUE, maxit=50, tol = 10^(-4))
{
  if( missing(my_col_pos))
  {
    my_col_pos <- rep( "black", dim(X)[2])
  }

  #To solve some strange issue related to argument calling when using simu_full() function,
  #I put this  function here
  #Itshould be outside of IBSS_MS

  if (missing(pos))
  {
    pos <- 1:dim(Y)[2]
  }



  ###########
  #Description
  #function to obtain the fitted effect from a Single effect Wavelet regression
  #Depend on more parameters than the one currently in place, these parameters stay fix during a SuSIe.





  #reshapping of the data
  if ( !(length(pos)==dim(Y)[2])) #miss matching positions and number of observations
  {
    stop("Error: number of position provided different from number of column of Y")
  }
  orignal_Y <-Y

  is.wholenumber <- function(x, tol = .Machine$double.eps^0.5)  abs(x - round(x)) < tol


  if(!is.wholenumber(log2(dim(Y)[2])) | !(sum( duplicated(diff( pos)))== (length(pos) -2)) ) #check wether dim(Y) not eqaul to 2^J or if the data are unevenly spaced
  {

    Y <- interpolKS(Y)
    bp<- (pos- min(pos))/(max(pos)-min(pos))
    outing_grid <- max(pos)*wavethresh::makegrid(t=bp,y=rep(0, length(pos)), gridn = 2^(floor(log(length(pos)-1,2)) + 1)    )$gridt
    print( "Response matrix dimensions not equal to nx 2^J, J integer \n interpolation procedure used")
  }  else{

    outing_grid <- 1:dim(Y)[2]
  }
  ### utils -----


  #Interpollation procedure from Kovac and Silveramnn 2000, code from wavethresh package Guy Nason
  #Y a matrix of size  N x Ji where (Ji is the number of observed point by )

  interpolKS <- function(Y )
  {

    bp<- (pos- min(pos))/(max(pos)-min(pos))
    interpolation <-  function (y)
    {
      wavethresh::makegrid(t=bp,y=y, gridn = 2^(floor(log(length(pos)-1,2)) + 1)   )$gridy
    }
    inter_Y  <- apply( Y,1,  interpolation)
    out <- t(inter_Y)
  }




  #perform wavelet transform on matrices of size nx2^j
  DWT2 <- function (data, filter.number = 10, family = "DaubLeAsymm")
  {
    if (sum(methods::is(data) == c("numeric", "vector")) == 2) {
      data <- matrix(data, nrow = 1)
    }
    J <- ncol(data)
    n <- nrow(data)
    D <- matrix(NA, nrow = n, ncol = J - 1)
    C <- rep(NA, n)
    for (i in 1:n) {
      temp <- wd(data[i, ], filter.number = filter.number,
                 family = family)
      D[i, ] <- temp$D
      C[i] <- accessC(temp, level = 0)
    }
    output <- list(C = C, D = D, J = log2(J), filter.number = filter.number,
                   family = family)
    class(output) <- "DWT"
    return(output)
  }





  #G list of fitted ash prior
  #t column to applied the posterior computation
  #return a vector of posterior mean/sd
  post_ash <- function( G_prior ,Bhat,Shat )
  {
    get_t_col_post <- function(t){
      m <- G_prior [[1]]
      data <-  set_data(Bhat[,t] ,Shat[,t] )
      return(postmean(get_fitted_g(m),data))
    }

    out <- lapply(1:(dim(Y)[2] ),get_t_col_post )

    return(do.call(cbind, out))
  }
  post_sd <- function( G_prior ,Bhat,Shat )
  {
    get_t_col_post <- function(t){
      m <- G_prior [[1]]
      data <-  set_data(Bhat[,t] ,Shat[,t] )
      return(postsd(get_fitted_g(m),data))
    }

    out <- lapply(1:(dim(Y)[2] ),get_t_col_post )

    return(do.call(cbind, out))
  }


  ##fast linear via Rfast implementation
  # compute regression between wavelet coefficient l and covariation j
  #return beta and std error
  fit_lm <- function( l,j)
  {

    out <- lm.fit(cbind(v1,X[,j]),Y_f[,l])
    return(summary(out)$coefficients[2,1:2])
  }



  ##Defintion of static parameter ----

  P <- dim(X)[2]  #number of covariates
  N <- dim(X)[1]  #number of individuals
  m <- length(outing_grid)  #number of d wavelet coefficients, assuming dim(Y)[2]= 2^J
  if(m > 1024) #to prevent to analyse to fine grain data, wavetresh do njot support more than lev_res >10
  {
    lev_res <- 10
    print("Number of time points too large, analysis performed on reduced data containning 1024 time points")
  }else{
    lev_res <- which(m/(2^(1:10)) ==1)
  }
  v1 <- rep(1, dim(X)[1])### used in fit_lm to add a column of 1 in the design matrix

  ####### dynamic parameter -------------
  #Intialisation and declaration of the dynamic parameter

  log_BF_row      <- list() #logarithmic Bayes factors row prior
  log_BF_col      <- list() #logarithmic Bayes factors  col prior
  fitted_wc_row   <- list()#fitted coefficient for function specific prior
  fitted_wc_col   <- list()# fitted coef for wavelet coeff  specific prior
  fitted_wc_row2  <- list()#varaince est coeff for function specific prior
  fitted_wc_col2   <- list()#varaince est coeff wit wavelet coeff  specific prior
  alpha_row       <- list()#PiP
  alpha_col       <- list()#PiP
  alpha_row_hist  <- list() # hist PiP
  alpha_col_hist  <- list() # hist PiP
  fitted_func <- list()
  check <- 1 # paramter to check convergence
  for ( l in 1:L) #initialize all the coefficients to zero
  {

    fitted_wc_row[[l]]  <- matrix(0,ncol=m,nrow=P)
    fitted_wc_col[[l]]  <- matrix(0,ncol=m,nrow=P)
    alpha_row[[l]]      <- rep(0,P)
    alpha_col[[l]]      <- rep(0,P)
  }

  Bhat  <- list()
  Shat  <- list()




  ###### #Wavelet transform of the dat  ----------





  ##### fittting prior ---------


  #### G with s,l specific prior ---------

  fit_lm <- function( l,j)
  {

    out <- lm.fit(cbind(v1,X[,j]),Y_f[,l])
    return(c(out$coefficients[2],
             sqrt(var(out$residuals)/sum((X[,j]-mean(X[,j]))^2))))
  }

  get_log_BF <- function( G_prior  ,Bhat,Shat )
  {
    get_t_col_post <- function(t ){


      m <- (G_prior [[1]]   )

      m$fitted_g$sd <- sqrt(m$fitted_g$sd^2 +mean(Shat[t,  ])^2)#here mean(Shat[t,  ]) is sigma_f in the current draft, nosie varaince
      return(sum( log( (get_density(m,Bhat[t,  ])$y) )    -   log(dnorm(  Bhat[t,  ],sd= mean(Shat[t,  ]))) ))
    }
    out <- lapply( 1:(dim(X)[2]),
                   FUN= get_t_col_post)

    return(do.call(c, out))
  }


  ##### fitting the ash priors


  W <- DWT2(Y)
  update_D <- W
  Y_f <- cbind(W$D, W$C) #Using a column like phenotype
  lev_res <- log2(dim(Y_f))[2]
  #Data to fit  ash
  #compute regression coefficient whitun the reiudals
  Bhat  <- list()
  Shat  <- list()

  for ( j in 1:dim(Y)[2])
  {
    out <- mapply(fit_lm, j,1:dim(X)[2])
    Bhat[[j]]  <- out[1,]
    Shat[[j]] <- out[2,]
  }

  Bhat <- (do.call(cbind, Bhat))
  Shat <- (do.call(cbind, Shat))


  #fit an ash prior using coefficient in column t in matrices Bhat (reg coeff) and Shat (standard error)

  G_prior <- list()

  G_prior[[1]]  <-  ash(c(Bhat), c(Shat),mixcompdist ="normal")


  log_lik_univ <- function(y,expected_y,sigma)
  {
    return(sum(dnorm(y, mean = expected_y, sd = sigma, log = TRUE)))
  }

  #variance when no effect
  sig0 <- apply(Y_f, 2, mad)
  log_lik_univ_0 <- function(t){
    -log_lik_univ(Y_f[,t],rep(0, length(Y_f[,t])),sigma=sig0[t])
  }
  #log likelihood under the null
  log_lik0 <- sum(unlist((lapply(1:dim(Y_f)[2],log_lik_univ_0 ))))


  get_sig0 <- function(l,k)
  {
    res  <- Y_f - (X[,k] ) %*% t(fitted_wc_col[[l]][k,])
    return(apply(res, 2, mad))

  }


  #IBSS ash ---------
  if(verbose == TRUE)
  {
    print("starting IBSS")
  }
  h <- 0 #index of history of alpha
  if(L==1)
  {
    Bhat  <- list()
    Shat  <- list()
    #compute regression coefficient whitun the resiudals

    for ( j in 1:dim(Y)[2])
    {
      out <- mapply(fit_lm, j,1:dim(X)[2])
      Bhat[[j]]  <- out[1,]
      Shat[[j]] <- out[2,]
    }
    Bhat <- (do.call(cbind, Bhat))
    Shat <- (do.call(cbind, Shat))

    G_prior <- list()

    G_prior[[1]]  <-  ash(c(Bhat), c(Shat),mixcompdist ="normal")

    log_BF <-  get_log_BF(G_prior ,Bhat,Shat)
    if( prod(is.finite(log_BF) ) ==0 ) #avoid extrem overflow problem when little noise is present
    {
      log_BF <-  ifelse(log_BF==Inf,max(1000, 10*max(log_BF[-which(log_BF==Inf)])),log_BF)
      log_BF <-  ifelse(log_BF== -Inf,max(-1000, -10*max(log_BF[-which(log_BF== -Inf)])),log_BF)
    }
    alpha_col[[l]] <- exp(log_BF - max(log_BF ) ) /sum( exp(log_BF - max(log_BF ) )) #avoid overflow
  }else{
    while(check >tol & (h/L) <maxit)
    {



      for ( l in 1: L)
      {
        h <- h+1
        #l colmun of wavelet response matrix
        #j column of the covariate matrix
        #Fitting the effect variable by variable
        Bhat  <- list()
        Shat  <- list()
        #compute regression coefficient whitun the resiudals

        for ( j in 1:dim(Y)[2])
        {
          out <- mapply(fit_lm, j,1:dim(X)[2])
          Bhat[[j]]  <- out[1,]
          Shat[[j]] <- out[2,]
        }
        Bhat <- (do.call(cbind, Bhat))
        Shat <- (do.call(cbind, Shat))
        G_prior <- list()

        G_prior[[1]]  <-  ash(c(Bhat), c(Shat),mixcompdist ="normal")
        fitted_wc_col[[l]]   <- post_ash(G_prior , Bhat, Shat )
        fitted_wc_col2[[l]]  <- post_sd(G_prior , Bhat, Shat )

        log_BF <-  get_log_BF(G_prior ,Bhat,Shat)
        if( prod(is.finite(log_BF) ) ==0 ) #avoid extrem overflow problem when little noise is present
        {
          log_BF <-  ifelse(log_BF==Inf,max(1000, 10*max(log_BF[-which(log_BF==Inf)])),log_BF)
          log_BF <-  ifelse(log_BF== -Inf,max(-1000, -10*max(log_BF[-which(log_BF== -Inf)])),log_BF)
        }
        alpha_col[[l]] <- exp(log_BF - max(log_BF ) ) /sum( exp(log_BF - max(log_BF ) )) #avoid overflow
        if(verbose ==TRUE)
        {
          plot(alpha_col[[l]], main = paste("loop", ceiling(h/L), "effect",l))
        }

        id_L <- (1:L)[ - ( (l%%L)+1) ]#Computing residuals R_{l+1} by removing all the effect except effect l+1
        update_D$D <-  W$D -Reduce("+", lapply  ( id_L, function(l) (X*rep(alpha_col[[l]], rep.int(N,P))) %*% (fitted_wc_col[[l]][,-dim(fitted_wc_col[[l]])[2]])   ) )
        update_D$C <-  W$C -Reduce("+", lapply  ( id_L, function(l) (X*rep(alpha_col[[l]], rep.int(N,P))) %*% fitted_wc_col[[l]][,dim(fitted_wc_col[[l]])[2]] ) )
        Y_f <- cbind(  update_D$D,update_D$C )


        alpha_col_hist[[h]] <- alpha_col[[l]]

      }
      if(ceiling(h/L)>2)#update parameter convergebnce
      {
        check <-0
        for( tt in 0:(L-1))
        {
          check <-  check + var( alpha_col_hist[[h-tt]] -alpha_col_hist[[h-L-tt]])
        }

      }

    }
  }




  ##### Tidding output ----
  temp <- wd(rep(0, dim(Y_f)[2]))
  for ( l in 1:L)
  {


    temp$D <-    (alpha_col[[l]])%*%fitted_wc_col[[l]][,-dim(fitted_wc_col[[l]])[2]]
    temp$C[length(temp$C)] <- (alpha_col[[l]])%*%fitted_wc_col[[l]][,dim(fitted_wc_col[[l]])[2]]
    fitted_func[[l]] <- wr(temp)


  }


  ########################
  #Individual prediction -----
  ########################
  ind_fitted_func <- matrix(NA, ncol = m, nrow = N)
  for ( i in 1:N)
  {
    ind_fitted_func[i,]  <- rep(0,dim(Y_f)[2])#fitted_baseline
    for ( l in 1: L)
    {

      temp$D <-   (alpha_col[[l]] *X[i,])%*%fitted_wc_col[[l]][,-1]
      temp$C[length(temp$C)] <- (alpha_col[[l]] *X[i,]) %*%fitted_wc_col[[l]][,1]
      ind_fitted_func[i,]  <-  ind_fitted_func[i,]+wr(temp)
    }
  }



  #### Compute CS and PIP
  pip <- list()
  cs <- list()
  for( l in 1:L)
  {

    temp        <- alpha_col[[l]]
    temp_cumsum <- cumsum( temp[order(temp, decreasing =TRUE)])
    max_indx_cs <- min(which( temp_cumsum >0.95))
    cs[[l]]  <- order(temp, decreasing = TRUE)[1:max_indx_cs ]
    pip[[l]] <- rep(1, dim(X)[2])-alpha_col[[l]]
  }
  pip <- 1-  apply( do.call(rbind,pip),2, prod)

  out <- list( #fitted_baseline = fitted_baseline,
    pip             = pip,
    cs              = cs,
    fitted_wc       = fitted_wc_col ,
    fitted_func     = fitted_func,
    ind_pred        = ind_fitted_func,
    alpha           = alpha_col,
    alpha_hist      = alpha_col_hist,
    #elbohist        = elbohist,
    outing_grid     = outing_grid
  )

  return(out)
}

##### IBSS with wavelet coefficient prior ------------

#input

#Y functionnal phenotype, matrix of size N by size Ji, if Ji not of size J^2, automatic handling
#pos genomic position for each observation in Y, if missing suppose that the observation are evenly spaced
#X genotype matrix, matrix of size n by p in the current version all the elements have to be 0 or 1
#L the number of effect to fit (if not specified =2)
#my_col_pos color of the points for the alpha plot (for simulation)

#output
#pip Posterior inclusion probability,
#cs  Credible sets
#fitted_baseline, TO BE Implemented, vector of size 2^J, baseline in the original space, expected function when no effect.
#fitted_wc, list of length l, each element is a matrix of size 2^J x p containning the fitted wavelet coefficient for each effect.
#                            the column are the variable effect in the wavelet space, first element of the column correspond to the C coefficient
#                             the second correspond to the d coefficient (1,1), the third to the d coefficient (1,2), 4th (2,2), 5th (2,3) and so on
#fitted_func, list of length l, each element is a vector of length 2^J representing the fitted function for each effect (i.e. fitted_wc[[l]]%*%alpha[[l]] in the original space)
#ind_pred individual prediction of the model
#alpha
#alpha_history
#outing_grid, grid of size 2^J used to perform the wavelet transform. This correspond of the x axis of the fitted functions.
#est_pi0 list of the proportion of wavelet coefficients not affected by the selected covariate
IBSS_ash_sl <- function(Y,X, L=2,  plot_out =TRUE, my_col_pos, pos,verbose =TRUE, maxit=50, tol = 10^(-4))
{
  if( missing(my_col_pos))
  {
    my_col_pos <- rep( "black", dim(X)[2])
  }

  #To solve some strange issue related to argument calling when using simu_full() function,
  #I put this  function here
  #Itshould be outside of IBSS_MS

  if (missing(pos))
  {
    pos <- 1:dim(Y)[2]
  }
  interpolKS <- function(Y )
  {

    bp<- (pos- min(pos))/(max(pos)-min(pos))
    interpolation <-  function (y)
    {
      wavethresh::makegrid(t=bp,y=y, gridn = 2^(floor(log(length(pos)-1,2)) + 1)   )$gridy
    }
    inter_Y  <- apply( Y,1,  interpolation)
    out <- t(inter_Y)
  }




  ###########
  #Description
  #function to obtain the fitted effect from a Single effect Wavelet regression
  #Depend on more parameters than the one currently in place, these parameters stay fix during a SuSIe.





  #reshapping of the data
  if ( !(length(pos)==dim(Y)[2])) #miss matching positions and number of observations
  {
    stop("Error: number of position provided different from number of column of Y")
  }
  orignal_Y <-Y

  is.wholenumber <- function(x, tol = .Machine$double.eps^0.5)  abs(x - round(x)) < tol


  if(!is.wholenumber(log2(dim(Y)[2])) | !(sum( duplicated(diff( pos)))== (length(pos) -2)) ) #check wether dim(Y) not eqaul to 2^J or if the data are unevenly spaced
  {

    Y <- interpolKS(Y)
    bp<- (pos- min(pos))/(max(pos)-min(pos))
    outing_grid <- max(pos)*wavethresh::makegrid(t=bp,y=rep(0, length(pos)), gridn = 2^(floor(log(length(pos)-1,2)) + 1)    )$gridt
    print( "Response matrix dimensions not equal to nx 2^J, J integer \n interpolation procedure used")
  }  else{

    outing_grid <- 1:dim(Y)[2]
  }
  ### utils -----


  #Interpollation procedure from Kovac and Silveramnn 2000, code from wavethresh package Guy Nason
  #Y a matrix of size  N x Ji where (Ji is the number of observed point by )




  #perform wavelet transform on matrices of size nx2^j
  DWT2 <- function (data, filter.number = 10, family = "DaubLeAsymm")
  {
    if (sum(methods::is(data) == c("numeric", "vector")) == 2) {
      data <- matrix(data, nrow = 1)
    }
    J <- ncol(data)
    n <- nrow(data)
    D <- matrix(NA, nrow = n, ncol = J - 1)
    C <- rep(NA, n)
    for (i in 1:n) {
      temp <- wd(data[i, ], filter.number = filter.number,
                 family = family)
      D[i, ] <- temp$D
      C[i] <- accessC(temp, level = 0)
    }
    output <- list(C = C, D = D, J = log2(J), filter.number = filter.number,
                   family = family)
    class(output) <- "DWT"
    return(output)
  }





  #G list of fitted ash prior
  #t column to applied the posterior computation
  #return a vector of posterior mean/sd
  post_ash <- function( G_prior ,Bhat,Shat )
  {
    get_t_col_post <- function(t){
      m <- G_prior [[1]]
      data <-  set_data(Bhat[,t] ,Shat[,t] )
      return(postmean(get_fitted_g(m),data))
    }

    out <- lapply(1:(dim(Y)[2] ),get_t_col_post )

    return(do.call(cbind, out))
  }
  post_sd <- function( G_prior ,Bhat,Shat )
  {
    get_t_col_post <- function(t){
      m <- G_prior [[1]]
      data <-  set_data(Bhat[,t] ,Shat[,t] )
      return(postsd(get_fitted_g(m),data))
    }

    out <- lapply(1:(dim(Y)[2] ),get_t_col_post )

    return(do.call(cbind, out))
  }


  ##fast linear via Rfast implementation
  # compute regression between wavelet coefficient l and covariation j
  #return beta and std error
  fit_lm <- function( l,j)
  {

    out <- lm(Y_f[,l] ~ X[,j])
    return( summary(out)$coefficients[2,1:2]    )

  }

  log_BF_mix <- function(pi_k, sd_k, reg_coef_j, sd_coef_j)
  {

    tt <-  rep(0, length(reg_coef_j))
    for( k in 1:length(pi_k))
    {

      tt <- tt+ pi_k[k]*dnorm(reg_coef_j, sd= sqrt(sd_k[k]^2 +sd_coef_j^2), log=TRUE)

    }
    out <- sum ( tt  -    dnorm(  reg_coef_j,sd= sd_coef_j, log=TRUE))
  }

  ##Return a matrix L with j*t rows, where each row corresponds to a wavelet coefficient
  # row 1 corresponds to wave coeff for X[,1], row t+1 corresponds to wave coeff for X[, 2] etc
  #columns  L[j,k] is the log value of the kth mixture component density at the jth data point (mixsqp doc)
  #L argument as in the mix sq


  get_L_mixsq <- function(G_prior, Bhat, Shat )
  {
    m <-  (G_prior[[1]])
    tt <- list()
    for ( k in 1:length(m$fitted_g$pi))
    {



      tt [[k]] <- dnorm( c(Bhat), sd = (sqrt(m$fitted_g$sd[k]^2 +Shat)),
                         log = TRUE)
    }

    L  <- do.call(cbind,tt)

    return(L)
  }


  #old version
  EM_pi_mix <- function(G_prior,Bhat, Shat){

    #static parameters
    L_mixsq <- get_L_mixsq(G_prior, Bhat, Shat)
    max_step =100
    espsilon =0.0001
    #dynamic parameters
    tpi_k= (G_prior[[1]]$fitted_g$pi)
    tsd_k=G_prior[[1]]$fitted_g$sd
    J <- dim(Bhat)[1]
    oldloglik <-0
    newloglik <-1
    n_wav_coef <- dim(Bhat)[2]
    zeta <- rep(1/J,J)
    k <- 1

    e_log_BF_mix <- function(j)
    {
      return(
        log_BF_mix(pi_k=tpi_k,
                   sd_k=tsd_k,
                   reg_coef_j=Bhat[j,] ,
                   sd_coef_j= Shat[j,]
        )
      )
    }
    lBF <- do.call(c,lapply(1:J,e_log_BF_mix ))
    if( prod(is.finite(lBF) )==0) #avoid extrem overflow problem when little noise is present
    {
      lBF <-  ifelse(lBF==Inf,max(1000, 10*max(lBF[-which(lBF==Inf)])),lBF)
      lBF <-  ifelse(lBF== -Inf,max(-1000, -10*max(lBF[-which(lBF== -Inf)])),lBF)
    }

    while( k <max_step &  abs(newloglik-oldloglik)>=espsilon)
    {
      ###E step----
      #easier to plug into  a apply function
      #but pi_k, sd_k have to be updated at every loop


      oldloglik <- sum( zeta*exp(lBF - max(lBF ) ))
      zeta <- exp(lBF - max(lBF ) ) /sum( exp(lBF - max(lBF ) ))

      #zeta are the assignement proba/weight afterwards

      ####M step ---

      w <- rep(zeta,  n_wav_coef) #setting the weight to fit the wieghted ash problem
      tlength <- dim(L_mixsq)[2]-1
      out.mixsqp <- mixsqp(L_mixsq,
                           w,
                           log=TRUE,
                           x0 = c(1, rep(1e-30,  tlength )),
                           control = list(eps = 1e-6,
                                          numiter.em = 20,
                                          verbose=FALSE
                           )
      )
      tpi_k <- out.mixsqp$x


      lBF <- do.call(c,lapply(1:J,e_log_BF_mix ))
      if( prod(is.finite(lBF) )==0) #avoid extrem overflow problem when little noise is present
      {
        lBF <-  ifelse(lBF==Inf,max(1000, 10*max(lBF[-which(lBF==Inf)])),lBF)
        lBF <-  ifelse(lBF== -Inf,max(-1000, -10*max(lBF[-which(lBF== -Inf)])),lBF)
      }
      newloglik <- sum( zeta*exp(lBF - max(lBF ) ))


      k <- k+1

    }
    out =list (tpi_k=tpi_k,
               lBF =lBF )
    return(out )
  }

  ##Defintion of static parameter ----

  P <- dim(X)[2]  #number of covariates
  N <- dim(X)[1]  #number of individuals
  m <- length(outing_grid)  #number of d wavelet coefficients, assuming dim(Y)[2]= 2^J
  if(m > 1024) #to prevent to analyse to fine grain data, wavetresh do njot support more than lev_res >10
  {
    lev_res <- 10
    print("Number of time points too large, analysis performed on reduced data containning 1024 time points")
  }else{
    lev_res <- which(m/(2^(1:10)) ==1)
  }
  v1 <- rep(1, dim(X)[1])### used in fit_lm to add a column of 1 in the design matrix

  ####### dynamic parameter -------------
  #Intialisation and declaration of the dynamic parameter

  log_BF_row      <- list() #logarithmic Bayes factors row prior
  log_BF_col      <- list() #logarithmic Bayes factors  col prior
  fitted_wc_row   <- list()#fitted coefficient for function specific prior
  fitted_wc_col   <- list()# fitted coef for wavelet coeff  specific prior
  fitted_wc_row2  <- list()#varaince est coeff for function specific prior
  fitted_wc_col2   <- list()#varaince est coeff wit wavelet coeff  specific prior
  alpha_row       <- list()#PiP
  alpha_col       <- list()#PiP
  alpha_row_hist  <- list() # hist PiP
  alpha_col_hist  <- list() # hist PiP
  pi_prior_list   <-  list() #store previously fitted pi to use as EM starting point next setp (speed gain)
  fitted_func <- list()
  check <- 1 # paramter to check convergence
  for ( l in 1:L) #initialize all the coefficients to zero
  {

    fitted_wc_row[[l]]  <- matrix(0,ncol=m,nrow=P)
    fitted_wc_col[[l]]  <- matrix(0,ncol=m,nrow=P)
    alpha_row[[l]]      <- rep(0,P)
    alpha_col[[l]]      <- rep(0,P)
  }

  Bhat  <- list()
  Shat  <- list()




  ###### #Wavelet transform of the dat  ----------





  ##### fittting prior ---------


  #### G with s,l specific prior ---------



  fit_lm <- function( l,j)
  {

    out <- lmfit(cbind(v1,X[,j]),Y_f[,l])
    return(c(out$be[2,1],
             sqrt(
               var(out$residuals)/sum(
                 (X[,j]-mean(X[,j]))^2)
             )
    )
    )

  }
  get_log_BF <- function( G_prior  ,Bhat,Shat )
  {
    get_t_col_post <- function(t ){


      m <- (G_prior [[1]]   )

      m$fitted_g$pi
      tt <-  rep(0, length(Shat[t,  ]))
      pi_k <- m$fitted_g$pi
      sd_k <- m$fitted_g$sd
      for( k in 1:length( m$fitted_g$pi)) #could potentiall skip the one that are exactly 0
      {

        tt <- tt+ pi_k[k]*dnorm(Bhat[t,  ], sd= sqrt(sd_k[k]^2 +Shat[t,  ]^2))

      }
      out <- sum (log(tt) -   log(dnorm(  Bhat[t,  ],sd= Shat[t,  ])))

      return( out )
    }
    out <- lapply( 1:(dim(X)[2]),
                   FUN= get_t_col_post)

    return(do.call(c, out))
  }





  ##### fitting the ash priors


  W <- DWT2(Y)
  update_D <- W
  Y_f <- cbind(W$D,W$C) #Using a column like phenotype
  lev_res <- log2(dim(Y_f))[2]
  #Data to fit  ash
  #compute regression coefficient whitun the reiudals
  Bhat  <- list()
  Shat  <- list()

  for ( j in 1:dim(Y)[2])
  {
    out <- mapply(fit_lm, j,1:dim(X)[2])
    Bhat[[j]]  <- out[1,]
    Shat[[j]] <- out[2,]
  }

  Bhat <- (do.call(cbind, Bhat))
  Shat <- (do.call(cbind, Shat))


  #fit an ash prior using coefficient in column t in matrices Bhat (reg coeff) and Shat (standard error)

  G_prior <- list()

  G_prior[[1]]  <-  ash(c(Bhat), c(Shat),mixcompdist ="normal")

  for ( l in 1:L)
  {
    pi_prior_list[[l]] <- G_prior[[1]]$fitted_g$pi
  }
  #IBSS ash ---------
  if(verbose == TRUE)
  {
    print("starting IBSS")
  }
  h <- 0 #index of history of alpha
  if(L==1)
  {
    Bhat  <- list()
    Shat  <- list()
    #compute regression coefficient whitun the resiudals

    for ( j in 1:dim(Y)[2])
    {
      out <- mapply(fit_lm, j,1:dim(X)[2])
      Bhat[[j]]  <- out[1,]
      Shat[[j]] <- out[2,]
    }
    Bhat <- (do.call(cbind, Bhat))
    Shat <- (do.call(cbind, Shat))

    t_prior <- G_prior

    EM_out <- EM_pi_mix(G_prior= t_prior, Bhat,Shat)
    t_prior[[1]]$fitted_g$pi <-  EM_out$tpi_k
    fitted_wc_col[[l]]   <- post_ash(t_prior , Bhat, Shat )
    fitted_wc_col2[[l]]  <- post_sd(t_prior , Bhat, Shat )
    log_BF <- EM_out$lBF
    alpha_col[[l]] <- exp(log_BF - max(log_BF ) ) /sum( exp(log_BF - max(log_BF ) )) #avoid overflow
  }else{
    while(check >tol & (h/L) <maxit)
    {



      for ( l in 1: L)
      {
        h <- h+1
        #l colmun of wavelet response matrix
        #j column of the covariate matrix
        #Fitting the effect variable by variable
        Bhat  <- list()
        Shat  <- list()
        #compute regression coefficient whitun the resiudals

        for ( j in 1:dim(Y)[2])
        {
          out <- mapply(fit_lm, j,1:dim(X)[2])
          Bhat[[j]]  <- out[1,]
          Shat[[j]] <- out[2,]
        }
        Bhat <- (do.call(cbind, Bhat))
        Shat <- (do.call(cbind, Shat))

        t_prior <- G_prior
        EM_out <- EM_pi_mix(G_prior= t_prior, Bhat,Shat)
        t_prior[[1]]$fitted_g$pi <-  EM_out$tpi_k
        fitted_wc_col[[l]]   <- post_ash(t_prior , Bhat, Shat )
        fitted_wc_col2[[l]]  <- post_sd(t_prior , Bhat, Shat )
        log_BF <- EM_out$lBF

        alpha_col[[l]] <- exp(log_BF - max(log_BF ) ) /sum( exp(log_BF - max(log_BF ) )) #avoid overflow
        #avoid overflow
        if(verbose ==TRUE)
        {
          plot(alpha_col[[l]], main = paste("loop", ceiling(h/L), "effect",l))
        }
        id_L <- (1:L)[ - ( (l%%L)+1) ]#Computing residuals R_{l+1} by removing all the effect except effect l+1
        update_D$D <-  W$D -Reduce("+", lapply  ( id_L, function(l) (X*rep(alpha_col[[l]], rep.int(N,P))) %*% (fitted_wc_col[[l]][,-dim(fitted_wc_col[[l]])[2]])   ) )
        update_D$C <-  W$C -Reduce("+", lapply  ( id_L, function(l) (X*rep(alpha_col[[l]], rep.int(N,P))) %*% fitted_wc_col[[l]][,dim(fitted_wc_col[[l]])[2]] ) )
        Y_f <- cbind(  update_D$D,update_D$C )


        alpha_col_hist[[h]] <- alpha_col[[l]]

      }
      if(ceiling(h/L)>2)#update parameter convergebnce
      {
        check <-0
        for( tt in 0:(L-1))
        {
          check <-  check + var( alpha_col_hist[[h-tt]] -alpha_col_hist[[h-L-tt]])
        }

      }

    }
  }



  ##### Tidding output ----
  temp <- wd(rep(0, dim(Y_f)[2]))
  for ( l in 1:L)
  {


    temp$D <-       (alpha_col[[l]])%*%fitted_wc_col[[l]][,-dim(fitted_wc_col[[l]])[2]]
    temp$C[length(temp$C)] <- (alpha_col[[l]])%*%fitted_wc_col[[l]][,dim(fitted_wc_col[[l]])[2]]
    fitted_func[[l]] <- wr(temp)


  }


  ########################
  #Individual prediction -----
  ########################
  ind_fitted_func <- matrix(NA, ncol = m, nrow = N)
  for ( i in 1:N)
  {
    ind_fitted_func[i,]  <- rep(0,dim(Y_f)[2])#fitted_baseline
    for ( l in 1: L)
    {

      temp$D <-   (alpha_col[[l]] *X[i,])%*%fitted_wc_col[[l]][,-dim(fitted_wc_col[[l]])[2]]
      temp$C[length(temp$C)] <- (alpha_col[[l]] *X[i,]) %*%fitted_wc_col[[l]][,dim(fitted_wc_col[[l]])[2]]
      ind_fitted_func[i,]  <-  ind_fitted_func[i,]+wr(temp)
    }
  }



  #### Compute CS and PIP
  pip <- list()
  cs <- list()
  for( l in 1:L)
  {

    temp        <- alpha_col[[l]]
    temp_cumsum <- cumsum( temp[order(temp, decreasing =TRUE)])
    max_indx_cs <- min(which( temp_cumsum >0.95))
    cs[[l]]  <- order(temp, decreasing = TRUE)[1:max_indx_cs ]
    pip[[l]] <- rep(1, dim(X)[2])-alpha_col[[l]]
  }
  pip <- 1-  apply( do.call(rbind,pip),2, prod)

  out <- list( #fitted_baseline = fitted_baseline,
    pip             = pip,
    cs              = cs,
    fitted_wc       = fitted_wc_col ,
    fitted_func     = fitted_func,
    ind_pred        = ind_fitted_func,
    alpha           = alpha_col,
    alpha_hist      = alpha_col_hist,
    #elbohist        = elbohist,
    outing_grid     = outing_grid,
    est_pi0         = lapply(pi_prior_list, function(x) x[1])

  )

  return(out)
}





#Number of individuals

N = 50

#Number of covariates

P = 50

#root signal noise ratio
rsnr   <- 0.2

#Choosing which variable will have an effect
pos1 <- 1
pos2 <- 2




G = matrix(sample(c(0, 1,2), size=N*P, replace=T), nrow=N, ncol=P) #Genotype
beta0       <- 0
beta1       <- 1
beta2       <- 1
noisy.data  <- list()
idx <- sample( size =3, 1:4)#sample at random the different function for basaline/effect
for ( i in 1:N)
{
  test_func <- wavethresh::DJ.EX(n = 1024, rsnr = rsnr, noisy = TRUE )
  f0        <- beta0*test_func[[idx[1]]] #Baseline
  f1        <- test_func[[idx[2]]]
  f2        <- test_func[[idx[3]]]
  noisy.data [[i]] <-  beta0*f0 +  beta1*G[i,pos1]*f1 + beta2*G[i,pos2]*f2

}
noisy.data <- do.call(rbind, noisy.data)
test_func <- wavethresh::DJ.EX(n = 1024,   noisy = FALSE )
f0        <- beta0*test_func[[idx[1]]] #Baseline
f1        <- test_func[[idx[2]]]
f2        <- test_func[[idx[3]]]
plot(f0-0.1,
     type="l",
     main="Underlying function depending on the SNP",
     ylim=c(3*min(f0,f1,f2),3*max(f0,f1,f2)),
     ylab="y",
     xlab="time"
)
lines(f1+0.1+f0, col="red")
lines(f2-0.2+f0, col="green")
lines(f1+f2+f0+0.3, col="blue")
legend(x = c(0),
       y= 100,
       c("0,0", "1,0", "0,1","1,1"),
       col= c("black", "red","green", "blue"),
       lty = rep(1,4)
)




#Generating individual curve sample with noise, parameter rsnr in the loop below




plot( noisy.data[1,],
      col= "black",
      type ="l",
      ylim=c(-150,150),
      ylab="y",
      xlab="time",
      main="Observed noisy curves"
)
for ( i  in 2: N)
{
  if( G[i, 1]==0  & G[i,2]==0)
  {
    my_col <- "black"
  }

  if( G[i, 1]>0  & G[i,2]==0)
  {
    my_col <- "red"
  }
  if( G[i, 1]==0  & G[i,2]>0)
  {
    my_col <- "green"
  }
  if( G[i, 1]>0  & G[i,2]>0)
  {
    my_col <- "blue"
  }

  lines( noisy.data[i,], col=   my_col)
}
legend(x = c(0),
       y= -5,
       c("0,0", "1,0", "0,1","1,1"),
       col= c("black", "red","green", "blue"),
       lty = rep(1,4)
)
Y <- noisy.data
X <- G
out <-IBSS_per_level(Y=Y,X=X , verbose = FALSE)
out2 <-IBSS_ash_sl(Y=Y,X=X , verbose = FALSE)

out$pip
out$pip[order(out$pip)]
out$cs
plot(f2,type="l")
lines(out2$fitted_func[[2]], col="green")

lines(out$fitted_func[[2]], col="blue")
plot(f1, type="l")
lines(out2$fitted_func[[1]], col="green")


lines(out$fitted_func[[1]],col="blue")
  log(1-out$pip)
  log(1-out2$pip)
