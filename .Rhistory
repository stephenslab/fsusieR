expect_equal( susiF_obj$fitted_wc2[[1]],post_mat_sd  ( G_prior , Bhat, Shat , indx_lst))
expect_equal( get_alpha (susiF_obj , 1), cal_zeta(outEM$lBF))
expect_equal( get_G_prior(susiF_obj) ,G_prior)
}
)
test_that("The partial residual should be    ",
{
outEM <-  EM_pi(G_prior,Bhat,Shat, indx_lst)
G_prior <- update_prior(G_prior,
tpi= outEM$tpi_k )
susiF_obj <- update_susiF_obj(susiF_obj, 1, outEM, Bhat, Shat, indx_lst )
update_T <- cal_partial_resid(
susiF.obj = susiF_obj,
l         = 1,
X         = X,
D         = W$D,
C         = W$C,
L         = 1,
indx_lst  = indx_lst
)
id_L <-1
update_D  <-  W$D - Reduce("+", lapply  ( id_L, function(l) (X*rep(susiF_obj$alpha[[l]], rep.int(N,P))) %*% (susiF_obj$fitted_wc[[l]][,-dim(susiF_obj$fitted_wc[[l]])[2]])  ) )
update_C  <-  W$C - Reduce("+", lapply  ( id_L, function(l) (X*rep(susiF_obj$alpha[[l]], rep.int(N,P))) %*% susiF_obj$fitted_wc[[l]][,dim(susiF_obj$fitted_wc[[l]])[2]] ) )
manual_update <- cbind(  update_D, update_C)
expect_equal(  update_T ,manual_update)
}
)
test_that("The output update should be equal to    ",
{
outEM <-  EM_pi(G_prior,Bhat,Shat, indx_lst)
G_prior <- update_prior(G_prior,
tpi= outEM$tpi_k )
susiF_obj <- update_susiF_obj(susiF_obj, 1, outEM, Bhat, Shat, indx_lst )
tcs <- list()
tpip <- list()
for ( l in 1:susiF_obj$L)
{
temp        <- susiF_obj$alpha[[l]]
temp_cumsum <- cumsum( temp[order(temp, decreasing =TRUE)])
max_indx_cs <- min(which( temp_cumsum >0.95))
max_indx_cs <- min(which( temp_cumsum >0.95))
tcs[[l]]  <- order(temp, decreasing = TRUE)[1:max_indx_cs ]
tpip[[l]] <- rep(1, lengths(susiF_obj$alpha)[[l]])-susiF_obj$alpha[[l]]
}
pip <- 1-  apply( do.call(rbind,tpip),2, prod)
fitted_func <- list ()
temp <- wd(rep(0, dim(Y_f)[2]))
for ( l in 1:susiF_obj$L)
{
temp$D <-    (susiF_obj$alpha[[l]])%*%susiF_obj$fitted_wc[[l]][,-indx_lst[[length(indx_lst)]]]
temp$C[length(temp$C)] <- (susiF_obj$alpha[[l]])%*%susiF_obj$fitted_wc[[l]][,indx_lst[[length(indx_lst)]]]
fitted_func[[l]] <- wr(temp)
}
ind_fitted_func  <- matrix(0, ncol=dim(Y)[2], nrow=dim(Y)[1])
for ( i in 1:dim(Y)[1])
{
ind_fitted_func[i,]  <- rep(0,dim(Y)[2])#fitted_baseline
for ( l in 1:susiF_obj$L)
{
#add wavelet coefficient
temp$D                         <-    (susiF_obj$alpha[[l]] *X[i,])%*%susiF_obj$fitted_wc[[l]][,-indx_lst[[length(indx_lst)]]]
temp$C[length(temp$C)]         <-    (susiF_obj$alpha[[l]] *X[i,])%*%susiF_obj$fitted_wc[[l]][,indx_lst[[length(indx_lst)]]]
#transform back
ind_fitted_func[i,]  <-  ind_fitted_func[i,]+wr(temp)
}
}
expect_equal(  update_cal_pip(susiF_obj)$pip        ,pip)
expect_equal(  update_cal_cs(susiF_obj)$cs          ,tcs)
expect_equal(  update_cal_indf(susiF_obj, Y, X, indx_lst)$ind_fitted_func ,ind_fitted_func)
expect_equal(  update_cal_fit_func(susiF_obj, indx_lst)$fitted_func   ,fitted_func)
expect_equal(  out_prep(susiF_obj,Y, X=X, indx_lst=indx_lst)$pip        ,pip)
expect_equal(  out_prep(susiF_obj,Y, X=X, indx_lst=indx_lst)$cs          ,tcs)
expect_equal(  out_prep(susiF_obj,Y, X=X, indx_lst=indx_lst)$ind_fitted_func ,ind_fitted_func)
expect_equal(  out_prep(susiF_obj,Y, X=X, indx_lst=indx_lst)$fitted_func   ,fitted_func)
}
)
test_that("The precision of the fitted curves should be   ",
{
outEM <-  EM_pi(G_prior,Bhat,Shat, indx_lst)
G_prior <- update_prior(G_prior,
tpi= outEM$tpi_k )
susiF_obj <- update_susiF_obj(susiF_obj, 1, outEM, Bhat, Shat, indx_lst )
expect_equal(  sum( abs(unlist(update_cal_fit_func(susiF_obj, indx_lst)$fitted_func) -f1$sim_func)), 0, tol=0.03)
}
)
outEM <-  EM_pi(G_prior,Bhat,Shat, indx_lst)
G_prior <- update_prior(G_prior,
tpi= outEM$tpi_k )
susiF_obj <-  update_susiF_obj(susiF_obj, 1, outEM, Bhat, Shat, indx_lst )
susiF_obj <-  out_prep(susiF_obj,Y, X=X, indx_lst=indx_lst)
plot( unlist(susiF_obj$fitted_func), type="l", col="green")
lines(f1$sim_func, col="red")
test_that("SusiF performance should be",
{
set.seed(1)
sim  <- simu_test_function(rsnr=2,is.plot = FALSE)
Y <- sim$noisy.data
X <- sim$G
out <- susiF(Y,X,L=1, prior="mixture_normal")
expect_equal(  unlist( out$alpha) , c(1, rep(0,9)) , tol=1e-5)
expect_equal(  sum( abs(unlist(out$fitted_func) -sim$f1)), 0, tol=0.2*length(sim$f1))
}
)
test_that("SusiF performance should be",
{
set.seed(1)
sim  <- simu_test_function(rsnr=2,pos2= 2 ,is.plot = FALSE)
Y <- sim$noisy.data
X <- sim$G
out <- susiF(Y,X,L=2, prior="mixture_normal")
expect_equal(  Reduce("+", out$alpha) , c(1, 1,rep(0,8)) , tol=1e-5)
expect_equal( max(  sum( abs(unlist(out$fitted_func[[1]]) -sim$f1)),
sum( abs(unlist(out$fitted_func[[1]]) -sim$f2))
)
, 0, tol=0.2*length(sim$f1))
expect_equal( max(  sum( abs(unlist(out$fitted_func[[2]]) -sim$f1)),
sum( abs(unlist(out$fitted_func[[2]]) -sim$f2))
)
, 0, tol=0.2*length(sim$f1))
}
)
N = 50
#Number of covariates
P = 10
#root signal noise ratio
rsnr   <- 2
#Choosing which variable will have an effect
pos1 <- 1
pos2 <- 2
G = matrix(sample(c(0, 1,2), size=N*P, replace=T), nrow=N, ncol=P) #Genotype
beta0       <- 0
beta1       <- 1
beta2       <- 1
noisy.data  <- list()
idx <- sample( size =3, 1:4)#sample at random the different function for basaline/effect
for ( i in 1:N)
{
test_func <- wavethresh::DJ.EX(n = 128, rsnr = rsnr, noisy = TRUE )
f0        <- beta0*test_func[[idx[1]]] #Baseline
f1        <- test_func[[idx[2]]]
f2        <- test_func[[idx[3]]]
noisy.data [[i]] <-  beta0*f0 +  beta1*G[i,pos1]*f1 + beta2*G[i,pos2]*f2
}
noisy.data <- do.call(rbind, noisy.data)
test_func <- wavethresh::DJ.EX(n = 128,   noisy = FALSE )
f0        <- beta0*test_func[[idx[1]]] #Baseline
f1        <- test_func[[idx[2]]]
f2        <- test_func[[idx[3]]]
plot(f0-0.1,
type="l",
main="Underlying function depending on the SNP",
ylim=c(3*min(f0,f1,f2),3*max(f0,f1,f2)),
ylab="y",
xlab="time"
)
lines(f1+0.1+f0, col="red")
lines(f2-0.2+f0, col="green")
lines(f1+f2+f0+0.3, col="blue")
legend(x = c(0),
y= 100,
c("0,0", "1,0", "0,1","1,1"),
col= c("black", "red","green", "blue"),
lty = rep(1,4)
)
#Generating individual curve sample with noise, parameter rsnr in the loop below
plot( noisy.data[1,],
col= "black",
type ="l",
ylim=c(-150,150),
ylab="y",
xlab="time",
main="Observed noisy curves"
)
for ( i  in 2: N)
{
if( G[i, 1]==0  & G[i,2]==0)
{
my_col <- "black"
}
if( G[i, 1]>0  & G[i,2]==0)
{
my_col <- "red"
}
if( G[i, 1]==0  & G[i,2]>0)
{
my_col <- "green"
}
if( G[i, 1]>0  & G[i,2]>0)
{
my_col <- "blue"
}
lines( noisy.data[i,], col=   my_col)
}
legend(x = c(0),
y= -5,
c("0,0", "1,0", "0,1","1,1"),
col= c("black", "red","green", "blue"),
lty = rep(1,4)
)
Y <- noisy.data
X <- G
out <- susiF(Y=Y,X=X,L=2 , verbose = TRUE)
sim  <- simu_test_function(N=100,rsnr=1,  lev_res= 6,is.plot = TRUE)
Y <- sim$noisy.data
X <- sim$G
out <- susiF(Y,X,L=1, prior="mixture_normal")
plot( sim$f1, type="l")
lines(unlist(out$fitted_func),col='red' )
out$est_pi
out <- susiF(Y,X,L=1, prior="mixture_normal_per_scale")
lines(unlist(out$fitted_func),col='green' )
out$est_pi
library(suisF.alpha)
devtools::load_all(".")
library(testthat)
library(ashr)
library(wavethresh)
library(Rfast)
library(mixsqp)
set.seed(2)
f1 <- simu_IBSS_per_level(lev_res=9, alpha=1, prop_decay =1.5)
plot(f1$sim_func, type="l", ylab="y")
N=500
P=10
set.seed(23)
G = matrix(sample(c(0, 1,2), size=N*P, replace=T), nrow=N, ncol=P) #Genotype
beta0       <- 0
beta1       <- 1
pos1 <- 5
noisy.data  <- list()
rsnr=10
for ( i in 1:N)
{
f1_obs <- f1$sim_func
noisy.data [[i]] <-   beta1*G[i,pos1]*f1_obs +  rnorm(length(f1$sim_func), sd=  (1/  rsnr ) *sd(f1$sim_func))
}
noisy.data <- do.call(rbind, noisy.data)
Y <- noisy.data
X <- G
W <- DWT2(Y)
update_D <- W
Y_f <- cbind( W$D,W$C) #Using a column like phenotype
update_Y <-Y_f
v1 <- rep(1, dim(X)[2])
tt <-  cal_Bhat_Shat(Y_f,X,v1)
indx_lst <- gen_wavelet_indx(9)
Bhat <- tt$Bhat
Shat <- tt$Shat
### Test validity normal mixture per scale -----
G_prior <- init_prior(Y=Y_f,
X=X,
prior="mixture_normal_per_scale",
v1=v1,
indx_lst = indx_lst)
lBF <- log_BF (G_prior, tt$Bhat, tt$Shat , indx_lst)
lBF
test_that("Max lBF should be in postion",
{
expect_equal(which.max(lBF),
pos1
)
}
)
test_that("susiF object pi are expected to be equal to ",
{
susiF_obj <- init_susiF_obj(L=2, G_prior,Y,X)
expect_equal(get_pi(susiF_obj,1), get_pi_G_prior(G_prior)
)
expect_equal(get_pi(susiF_obj,2), get_pi_G_prior(G_prior)
)
}
)
susiF_obj <- init_susiF_obj(L=1, G_prior,Y,X)
test_that("susiF object pi are expected to be equal to ",
{
susiF_obj <- init_susiF_obj(L=1, G_prior,Y,X)
expect_equal(get_pi(susiF_obj,1), get_pi_G_prior(G_prior)
)
}
)
test_that("susiF internal prior to be equal to ",
{
susiF_obj <- init_susiF_obj(L=2, G_prior,Y,X)
expect_equal(get_G_prior (susiF_obj ),  G_prior)
}
)
test_that("Class of the prior is", {
expect_equal(class(
init_prior(Y=Y_f,
X=X,
prior="mixture_normal_per_scale",
v1=v1,
indx_lst = indx_lst)
),
"mixture_normal_per_scale"
)
})
plot( Bhat,  post_mat_mean(G_prior,Bhat,Shat, indx_lst) )
plot( Shat,  (post_mat_sd(G_prior,Bhat,Shat, indx_lst) ))
test_that("Class of the proportions  is", {
expect_equal(class(get_pi_G_prior(G_prior))
,
"pi_mixture_normal_per_scale"
)
})
test_that("Class of the standard deviations  is", {
expect_equal(class(get_sd_G_prior(G_prior))
,
"sd_mixture_normal_per_scale"
)
})
L <- L_mixsq(G_prior, Bhat, Shat, indx_lst)
test_that("The likelihood computed by L_mixsqp should be of class", {
L <- L_mixsq(G_prior, Bhat, Shat, indx_lst)
expect_equal(class(L), "lik_mixture_normal_per_scale"
)
})
zeta <- cal_zeta(lBF)
test_that("The highest assignation should be equal to", {
zeta <- cal_zeta(lBF)
expect_equal(which.max(zeta), pos1
)
})
tpi <- m_step(L, zeta , indx_lst)
class(tpi)
test_that("The output of the m_step function should of the class", {
tpi <- m_step(L, zeta , indx_lst)
expect_equal( class(tpi),"pi_mixture_normal_per_scale"
)
})
test_that("The output of the m_step for the pi_0 should equal", {
tpi <- m_step(L, zeta , indx_lst)
expect_equal( get_pi0(tpi = tpi), c(0,0.5, rep(1, 8)),
tolerance = 0.01) #allow 1% error in the proportion estimation
})
G_update <- update_prior (G_prior, tpi)
tpi <- m_step(L, zeta , indx_lst)
tpi
get_pi0(tpi = tpi)
get_pi0.pi_mixture_normal_per_scale()
get_pi0.pi_mixture_normal_per_scale
unlist(lapply(tpi, function(y) y[[1]][1]) )
get_pi0(tpi = tpi)
#'@title Get mixture proportion for mixture normal prior
#'
#'@description
#'@param tpi  object of class pi_mixture_normal
#'@return A number between 0 and 1
#'@export
get_pi0.pi_mixture_normal_per_scale  <- function(tpi)
{
out <-    (unlist(lapply(tpi, function(y) y[[1]][1]) ))
return(out)
}
get_pi0(tpi)
tpi
expect_equal( get_pi0( tpi), c(0,0.5, rep(1, 8)),
tolerance = 0.01) #allow 1% error in the proportion estimation
################################## Define Methods ############################
#'
#'
#'
log_BF              <- function( G_prior , ...)   UseMethod("log_BF")
post_mat_mean       <- function( G_prior , ...)   UseMethod("post_mat_mean")
post_mat_sd         <- function( G_prior , ...)   UseMethod("post_mat_sd")
get_pi_G_prior      <- function( G_prior , ...)   UseMethod("get_pi_G_prior")
get_pi0             <- function( G_prior , ...)   UseMethod("get_pi0")
get_sd_G_prior      <- function( G_prior , ...)   UseMethod("get_sd_G_prior")
L_mixsq             <- function( G_prior , ...)   UseMethod("L_mixsq")
update_prior        <- function( G_prior , ...)   UseMethod("update_prior")
m_step              <- function( L , ...)         UseMethod("m_step")
get_pi0             <- function( tpi , ...)       UseMethod("get_pi0")
get_pi              <- function( susiF , ...)     UseMethod("get_pi")
get_G_prior         <- function( susiF , ...)     UseMethod("get_G_prior")
get_alpha           <- function( susiF , ...)     UseMethod("get_alpha")
update_alpha        <- function( susiF , ...)     UseMethod("update_alpha")
update_pi           <- function( susiF , ...)     UseMethod("update_pi")
cal_partial_resid   <- function( susiF , ...)     UseMethod("cal_partial_resid")
update_susiF_obj    <- function( susiF , ...)     UseMethod("update_susiF_obj")
update_cal_pip      <- function( susiF , ...)     UseMethod("update_cal_pip")
update_cal_cs       <- function( susiF , ...)     UseMethod("update_cal_cs")
update_cal_indf     <- function( susiF , ...)     UseMethod("update_cal_indf")
update_cal_fit_func <- function( susiF , ...)     UseMethod("update_cal_fit_func")
out_prep            <- function( susiF , ...)     UseMethod("out_prep")
test_that("The output of the m_step for the pi_0 should equal", {
tpi <- m_step(L, zeta , indx_lst)
expect_equal( get_pi0(tpi = tpi), c(0,0.5, rep(1, 8)),
tolerance = 0.01) #allow 1% error in the proportion estimation
})
library(testthat)
library(ashr)
library(wavethresh)
library(Rfast)
library(mixsqp)
set.seed(2)
f1 <- simu_IBSS_per_level(lev_res=9, alpha=1, prop_decay =1.5)
plot(f1$sim_func, type="l", ylab="y")
N=500
P=10
set.seed(23)
G = matrix(sample(c(0, 1,2), size=N*P, replace=T), nrow=N, ncol=P) #Genotype
beta0       <- 0
beta1       <- 1
pos1 <- 5
noisy.data  <- list()
rsnr=10
for ( i in 1:N)
{
f1_obs <- f1$sim_func
noisy.data [[i]] <-   beta1*G[i,pos1]*f1_obs +  rnorm(length(f1$sim_func), sd=  (1/  rsnr ) *sd(f1$sim_func))
}
noisy.data <- do.call(rbind, noisy.data)
Y <- noisy.data
X <- G
W <- DWT2(Y)
update_D <- W
Y_f <- cbind( W$D,W$C) #Using a column like phenotype
update_Y <-Y_f
v1 <- rep(1, dim(X)[2])
tt <-  cal_Bhat_Shat(Y_f,X,v1)
indx_lst <- gen_wavelet_indx(9)
Bhat <- tt$Bhat
Shat <- tt$Shat
### Test validity normal mixture per scale -----
G_prior <- init_prior(Y=Y_f,
X=X,
prior="mixture_normal_per_scale",
v1=v1,
indx_lst = indx_lst)
lBF <- log_BF (G_prior, tt$Bhat, tt$Shat , indx_lst)
lBF
test_that("Max lBF should be in postion",
{
expect_equal(which.max(lBF),
pos1
)
}
)
test_that("susiF object pi are expected to be equal to ",
{
susiF_obj <- init_susiF_obj(L=2, G_prior,Y,X)
expect_equal(get_pi(susiF_obj,1), get_pi_G_prior(G_prior)
)
expect_equal(get_pi(susiF_obj,2), get_pi_G_prior(G_prior)
)
}
)
susiF_obj <- init_susiF_obj(L=1, G_prior,Y,X)
test_that("susiF object pi are expected to be equal to ",
{
susiF_obj <- init_susiF_obj(L=1, G_prior,Y,X)
expect_equal(get_pi(susiF_obj,1), get_pi_G_prior(G_prior)
)
}
)
test_that("susiF internal prior to be equal to ",
{
susiF_obj <- init_susiF_obj(L=2, G_prior,Y,X)
expect_equal(get_G_prior (susiF_obj ),  G_prior)
}
)
test_that("Class of the prior is", {
expect_equal(class(
init_prior(Y=Y_f,
X=X,
prior="mixture_normal_per_scale",
v1=v1,
indx_lst = indx_lst)
),
"mixture_normal_per_scale"
)
})
plot( Bhat,  post_mat_mean(G_prior,Bhat,Shat, indx_lst) )
plot( Shat,  (post_mat_sd(G_prior,Bhat,Shat, indx_lst) ))
test_that("Class of the proportions  is", {
expect_equal(class(get_pi_G_prior(G_prior))
,
"pi_mixture_normal_per_scale"
)
})
test_that("Class of the standard deviations  is", {
expect_equal(class(get_sd_G_prior(G_prior))
,
"sd_mixture_normal_per_scale"
)
})
L <- L_mixsq(G_prior, Bhat, Shat, indx_lst)
test_that("The likelihood computed by L_mixsqp should be of class", {
L <- L_mixsq(G_prior, Bhat, Shat, indx_lst)
expect_equal(class(L), "lik_mixture_normal_per_scale"
)
})
zeta <- cal_zeta(lBF)
test_that("The highest assignation should be equal to", {
zeta <- cal_zeta(lBF)
expect_equal(which.max(zeta), pos1
)
})
tpi <- m_step(L, zeta , indx_lst)
class(tpi)
test_that("The output of the m_step function should of the class", {
tpi <- m_step(L, zeta , indx_lst)
expect_equal( class(tpi),"pi_mixture_normal_per_scale"
)
})
test_that("The output of the m_step for the pi_0 should equal", {
tpi <- m_step(L, zeta , indx_lst)
expect_equal( get_pi0(tpi = tpi), c(0,0.5, rep(1, 8)),
tolerance = 0.01) #allow 1% error in the proportion estimation
})
m_step.lik_mixture_normal_per_scale()
m_step.lik_mixture_normal_per_scale(L,zeta, indx_lst)
