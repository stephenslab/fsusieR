beta0       <- 0
beta1       <- 1
pos1 <- 5
noisy.data  <- list()
rsnr=0.25
for ( i in 1:N)
{
f1_obs <- f1
noisy.data [[i]] <-   beta1*G[i,pos1]*f1_obs +  rnorm(length(f1), sd=  (1/  rsnr ) *sd(f1))
}
noisy.data <- do.call(rbind, noisy.data)
set.seed(2)
f1 <- simu_IBSS_per_level(lev_res=9, alpha=1, prop_decay =1.5)
plot(kk$sim_func, type="l", ylab="y")
N=500
P=10
set.seed(23)
G = matrix(sample(c(0, 1,2), size=N*P, replace=T), nrow=N, ncol=P) #Genotype
beta0       <- 0
beta1       <- 1
pos1 <- 5
noisy.data  <- list()
rsnr=0.25
for ( i in 1:N)
{
f1_obs <- f1
noisy.data [[i]] <-   beta1*G[i,pos1]*f1_obs +  rnorm(length(f1), sd=  (1/  rsnr ) *sd(f1))
}
noisy.data <- do.call(rbind, noisy.data)
set.seed(2)
f1 <- simu_IBSS_per_level(lev_res=9, alpha=1, prop_decay =1.5)
plot(f1$sim_func, type="l", ylab="y")
N=500
P=10
set.seed(23)
G = matrix(sample(c(0, 1,2), size=N*P, replace=T), nrow=N, ncol=P) #Genotype
beta0       <- 0
beta1       <- 1
pos1 <- 5
noisy.data  <- list()
rsnr=0.5
for ( i in 1:N)
{
f1_obs <- f1$sim_func
noisy.data [[i]] <-   beta1*G[i,pos1]*f1_obs +  rnorm(length(f1), sd=  (1/  rsnr ) *sd(f1))
}
noisy.data <- do.call(rbind, noisy.data)
Y <- noisy.data
X <- G
Y_f <- DWT2(Y)
set.seed(2)
f1 <- simu_IBSS_per_level(lev_res=9, alpha=1, prop_decay =1.5)
plot(f1$sim_func, type="l", ylab="y")
N=500
P=10
set.seed(23)
G = matrix(sample(c(0, 1,2), size=N*P, replace=T), nrow=N, ncol=P) #Genotype
beta0       <- 0
beta1       <- 1
pos1 <- 5
noisy.data  <- list()
rsnr=0.5
for ( i in 1:N)
{
f1_obs <- f1$sim_func
noisy.data [[i]] <-   beta1*G[i,pos1]*f1_obs +  rnorm(length(f1$sim_func), sd=  (1/  rsnr ) *sd(f1$sim_func))
}
noisy.data <- do.call(rbind, noisy.data)
Y <- noisy.data
X <- G
Y_f <- DWT2(Y)
init_prior <- function(Y,X, prior,v1 , indx_lst )
{
if( prior == "mixture_normal")
{
temp <- get_Bhat_Shat(Y,X,v1 )   ## Speed Gain would be good to call directly get_Bhat_Shat in the ash function
G_prior <- list()
G_prior[[1]]  <-  ash(c(temp$Bhat), c(temp$Shat),mixcompdist ="normal")
setClass(G_prior) <- prior
}
if( prior == "mixture_normal_per_scale")
{
temp <- get_Bhat_Shat(Y,X,v1 )   ## Speed Gain would be good to call directly get_Bhat_Shat in the ash function
G_prior  <-  lapply(1: log2(dim(Y)[2]) ,
FUN= fit_ash_level, Bhat=temp$Bhat, temp$Shat, indx_lst )
#first log2(Y_f)+1 element of G_prior   are ash prior fitted per level coefficient on var 1
# element in  (log2(Y_f)+2):  2*( log2(Y_f)+1)   of G_prior   are ash prior fitted per level coefficient on var 2
setClass(G_prior) <- prior
}
G_prior  <-  lapply(1: length(indx_lst)  ,
FUN= fit_ash_level )
}
gen_wavelet_indx <- function(lev_res)
{
indx_lst <- list()
indx_lst[[1]] <- 2^lev_res -1 #coefficient
for ( s in 1:(lev_res-1))
{
indx  <- 2^(lev_res)- (2^((s+1))-1) :(2^s)
indx_lst[[s+1]] <- indx
}
indx_lst[[length(indx_lst)+1]] <- 2^lev_res# C coefficient
out <- indx_lst
return(out)
}
Y <- noisy.data
X <- G
Y_f <- DWT2(Y)
v1 <- rep(1, dim(X)[2])
indx_lst <- gen_wavelet_indx(9)
G <- init_prior(Y_f,X, prior="mixture_normal",indx_lst = indx_lst)
################################## SuSiF UTILITY FUNCTIONS ############################
#'
#'
#'
#'@title Initialise the prior
#'
#'@description generate list of object corresponding to the parameters of the prior set for analysis
#'@param Y  functional phenotype, matrix of size N by size J. The underlying algorithm uses wavelet which assume that J is of the form J^2. If J not a power of 2, susif internally remaps the data into grid of length 2^J
#'@param X matrix of size n by p in
#'@param prior Three choice are available "normal", "mixture_normal", "mixture_normal_per_scale"
#'@param indx_lst list generated by gen_wavelet_indx for the given level of resolution, used only with class \class{mixture_normal_per_scale}
#'@return an object of the class "normal", "mixture_normal" or "mixture_normal_per_scale"
init_prior <- function(Y,X, prior,v1 , indx_lst )
{
if( prior == "mixture_normal")
{
temp <- get_Bhat_Shat(Y,X,v1 )   ## Speed Gain would be good to call directly get_Bhat_Shat in the ash function
G_prior <- list()
G_prior[[1]]  <-  ash(c(temp$Bhat), c(temp$Shat),mixcompdist ="normal")
setClass(G_prior) <- prior
}
if( prior == "mixture_normal_per_scale")
{
temp <- get_Bhat_Shat(Y,X,v1 )   ## Speed Gain would be good to call directly get_Bhat_Shat in the ash function
G_prior  <-  lapply(1: log2(dim(Y)[2]) ,
FUN= fit_ash_level, Bhat=temp$Bhat, temp$Shat, indx_lst )
#first log2(Y_f)+1 element of G_prior   are ash prior fitted per level coefficient on var 1
# element in  (log2(Y_f)+2):  2*( log2(Y_f)+1)   of G_prior   are ash prior fitted per level coefficient on var 2
setClass(G_prior) <- prior
}
G_prior  <-  lapply(1: length(indx_lst)  ,
FUN= fit_ash_level )
}
#'@title Regress Y nxJ on X nxp
#'
#'@description regression coefficients (and sd) of the column wise regression
#'
#'@param Y  functional phenotype, matrix of size N by size J. The underlying algorithm uses wavelet which assume that J is of the form J^2. If J not a power of 2, susif internally remaps the data into grid of length 2^J
#'@param X matrix of size n by p in
#'@return list of two
#'
#'\item{Bhat} matrix pxJ regression coefficient, Bhat[j,t] corresponds to regression coefficient of Y[,t] on X[,j]
#'\item{Shat} matrix pxJ standard error, Shat[j,t] corresponds to standard error of the regression coefficient of Y[,t] on X[,j]
get_Bhat_Shat <- function(Y,X,v1 )
{
Bhat  <- list()
Shat  <- list()
for ( l in 1:dim(Y)[2])
{
out <-  do.call( cbind,lapply( 1:dim(X)[2], function(j) fit_lm(l= l,j=j, Y=Y,X=X, v1=v1  ) ) )
Bhat[[l]]  <- out[1,]
Shat[[l]] <- out[2,]
}
Bhat <- (do.call(cbind, Bhat))
Shat <- (do.call(cbind, Shat))
out  <- list( Bhat = Bhat,
Shat = Shat)
return(out)
}
#'@title Regress column l of Y on column j of X
#'
#'@description
#'
#'@param Y  functional phenotype, matrix of size N by size J. The underlying algorithm uses wavelet which assume that J is of the form J^2. If J not a power of 2, susif internally remaps the data into grid of length 2^J
#'@param X matrix of size n by p in
#'@return vector of 2 containing the regression coefficient and standard
fit_lm <- function( l,j,Y,X,v1)  ## Speed Gain
{
out <- lmfit(cbind(v1,X[,j]),Y[,l])
return(c(out$be[2,1],
sqrt(
var(out$residuals)/sum(
(X[,j]-mean(X[,j]))^2)
)
)
)
}
#'@title Fit ash of coefficient from scale s
#'
#'@description  #'
#'@param Bhat  matrix pxJ regression coefficient, Bhat[j,t] corresponds to regression coefficient of Y[,t] on X[,j]
#'@param Shat matrix pxJ standard error, Shat[j,t] corresponds to standard error of the regression coefficient of Y[,t] on X[,j]
#'@param s scale of interest
#'@param indx_list list generated by gen_wavelet_indx for the given level of resolution, used only with class \class{mixture_normal_per_scale}
#'@return an ash object
fit_ash_level <- function(Bhat, Shat,s,indx_lst)
{
out <- ash(c(Bhat[, indx_lst[[s]] ]),
c(Shat[, indx_lst[[s]] ])
,mixcompdist ="normal"
)
return(out)
}
#'@title Compute log Bayes Factor under mixture normal prior
#'
#'@description  #'
#'@param G_prior mixture normal prior
#'@param Bhat  matrix pxJ regression coefficient, Bhat[j,t] corresponds to regression coefficient of Y[,t] on X[,j]
#'@param Shat matrix pxJ standard error, Shat[j,t] corresponds to standard error of the regression coefficient of Y[,t] on X[,j]
#'@param indx_list list generated by gen_wavelet_indx for the given level of resolution, used only with class \class{mixture_normal_per_scale}
#'@return p log Bayes factor
get_log_BF.mxiture_normal <- function( G_prior  ,Bhat,Shat, indx_lst )
{
get_t_col_post <- function(t ){
m <- (G_prior [[1]]   )
m$fitted_g$pi
tt <-  rep(0, length(Shat[t,  ]))
pi_k <- m$fitted_g$pi
sd_k <- m$fitted_g$sd
for( k in 1:length( m$fitted_g$pi))  ## Speed Gain #could potential skip the one that are exactly 0
{
tt <- tt+ pi_k[k]*dnorm(Bhat[t,  ], sd= sqrt(sd_k[k]^2 +Shat[t,  ]^2))
}
out <- sum (log(tt) -   log(dnorm(  Bhat[t,  ],sd= Shat[t,  ])))
return( out )
}
out <- lapply( 1:(dim(X)[2]),
FUN= get_t_col_post)
return(do.call(c, out))
}
#'@title Compute log Bayes Factor under mixture normal per scale prior
#'
#'@description
#'@param G_prior mixture normal prior
#'@param Bhat  matrix pxJ regression coefficient, Bhat[j,t] corresponds to regression coefficient of Y[,t] on X[,j]
#'@param Shat matrix pxJ standard error, Shat[j,t] corresponds to standard error of the regression coefficient of Y[,t] on X[,j]
#'@param indx_list list generated by gen_wavelet_indx for the given level of resolution, used only with class \class{mixture_normal_per_scale}
#'@return p log Bayes factor
get_log_BF.mixture_normal_per_scale <- function( G_prior ,Bhat,Shat, indx_lst )
{
get_t_col_post <- function(t ){
get_t_s_post <- function(s){
m <- G_prior  [[(t-1)*(log2(dim(Bhat)[2] )+1)+s]] ## Speed Gain #could potential skip the one that are exactly 0
data <-  set_data(Bhat[t,indx_lst[[s]] ],
Shat[t, indx_lst[[s]] ]
)
return(calc_logLR (get_fitted_g(m),data))
}
return(sum(unlist(lapply(1:(log2(dim(Bhat)[2] )+1 ),#important to maintain the ordering of the wavethresh package !!!!
get_t_s_post ))))
}
out <- lapply( 1:(dim(Bhat)[1]),
FUN= get_t_col_post)
return(do.call(c, out))
}
Y <- noisy.data
X <- G
Y_f <- DWT2(Y)
v1 <- rep(1, dim(X)[2])
indx_lst <- gen_wavelet_indx(9)
G <- init_prior(Y_f,X, prior="mixture_normal",indx_lst = indx_lst)
G <- init_prior(Y=Y_f,X, prior="mixture_normal",indx_lst = indx_lst)
dim(Y_f)
Y <- noisy.data
X <- G
W <- DWT2(Y)
update_D <- W
Y_f <- cbind( W$D,W$C) #Using a column like phenotype
update_Y <-Y_f
v1 <- rep(1, dim(X)[2])
indx_lst <- gen_wavelet_indx(9)
G <- init_prior(Y=Y_f,X, prior="mixture_normal",indx_lst = indx_lst)
library(Rfast)
G <- init_prior(Y=Y_f,X, prior="mixture_normal",indx_lst = indx_lst)
G <- init_prior(Y=Y_f,X, prior="mixture_normal", v1=v1,indx_lst = indx_lst)
?setClass
init_prior <- function(Y,X, prior,v1 , indx_lst )
{
if( prior == "mixture_normal")
{
temp <- get_Bhat_Shat(Y,X,v1 )   ## Speed Gain would be good to call directly get_Bhat_Shat in the ash function
G_prior <- list()
G_prior[[1]]  <-  ash(c(temp$Bhat), c(temp$Shat),mixcompdist ="normal")
setClass(G_prior) <- "mixture_normal"
}
if( prior == "mixture_normal_per_scale")
{
temp <- get_Bhat_Shat(Y,X,v1 )   ## Speed Gain would be good to call directly get_Bhat_Shat in the ash function
G_prior  <-  lapply(1: log2(dim(Y)[2]) ,
FUN= fit_ash_level, Bhat=temp$Bhat, temp$Shat, indx_lst )
#first log2(Y_f)+1 element of G_prior   are ash prior fitted per level coefficient on var 1
# element in  (log2(Y_f)+2):  2*( log2(Y_f)+1)   of G_prior   are ash prior fitted per level coefficient on var 2
setClass(G_prior) <- prior
}
G_prior  <-  lapply(1: length(indx_lst)  ,
FUN= fit_ash_level )
}
G <- init_prior(Y=Y_f,X, prior="mixture_normal", v1=v1,indx_lst = indx_lst)
init_prior <- function(Y,X, prior,v1 , indx_lst )
{
if( prior == "mixture_normal")
{
temp <- get_Bhat_Shat(Y,X,v1 )   ## Speed Gain would be good to call directly get_Bhat_Shat in the ash function
G_prior <- list()
G_prior[[1]]  <-  ash(c(temp$Bhat), c(temp$Shat),mixcompdist ="normal")
class(G_prior) <- "mixture_normal"
}
if( prior == "mixture_normal_per_scale")
{
temp <- get_Bhat_Shat(Y,X,v1 )   ## Speed Gain would be good to call directly get_Bhat_Shat in the ash function
G_prior  <-  lapply(1: log2(dim(Y)[2]) ,
FUN= fit_ash_level, Bhat=temp$Bhat, temp$Shat, indx_lst )
#first log2(Y_f)+1 element of G_prior   are ash prior fitted per level coefficient on var 1
# element in  (log2(Y_f)+2):  2*( log2(Y_f)+1)   of G_prior   are ash prior fitted per level coefficient on var 2
class(G_prior) <- prior
}
G_prior  <-  lapply(1: length(indx_lst)  ,
FUN= fit_ash_level )
}
G <- init_prior(Y=Y_f,X, prior="mixture_normal", v1=v1,indx_lst = indx_lst)
set.seed(2)
f1 <- simu_IBSS_per_level(lev_res=9, alpha=1, prop_decay =1.5)
plot(f1$sim_func, type="l", ylab="y")
N=500
P=10
set.seed(23)
G = matrix(sample(c(0, 1,2), size=N*P, replace=T), nrow=N, ncol=P) #Genotype
beta0       <- 0
beta1       <- 1
pos1 <- 5
noisy.data  <- list()
rsnr=0.5
for ( i in 1:N)
{
f1_obs <- f1$sim_func
noisy.data [[i]] <-   beta1*G[i,pos1]*f1_obs +  rnorm(length(f1$sim_func), sd=  (1/  rsnr ) *sd(f1$sim_func))
}
noisy.data <- do.call(rbind, noisy.data)
Y <- noisy.data
X <- G
W <- DWT2(Y)
update_D <- W
Y_f <- cbind( W$D,W$C) #Using a column like phenotype
update_Y <-Y_f
v1 <- rep(1, dim(X)[2])
indx_lst <- gen_wavelet_indx(9)
G <- init_prior(Y=Y_f,X, prior="mixture_normal", v1=v1,indx_lst = indx_lst)
temp <- get_Bhat_Shat(Y,X,v1 )   ## Speed Gain would be good to call directly get_Bhat_Shat in the ash function
temp
G_prior <- list()
G_prior[[1]]  <-  ash(c(temp$Bhat), c(temp$Shat),mixcompdist ="normal")
class(G_prior) <- "mixture_normal"
G_prior
init_prior <- function(Y,X, prior,v1 , indx_lst )
{
if( prior == "mixture_normal")
{
temp <- get_Bhat_Shat(Y,X,v1 )   ## Speed Gain would be good to call directly get_Bhat_Shat in the ash function
G_prior <- list()
G_prior[[1]]  <-  ash(c(temp$Bhat), c(temp$Shat),mixcompdist ="normal")
class(G_prior) <- "mixture_normal"
}
if( prior == "mixture_normal_per_scale")
{
temp <- get_Bhat_Shat(Y,X,v1 )   ## Speed Gain would be good to call directly get_Bhat_Shat in the ash function
G_prior  <-  lapply(1: log2(dim(Y)[2]) ,
FUN= fit_ash_level, Bhat=temp$Bhat, temp$Shat, indx_lst )
#first log2(Y_f)+1 element of G_prior   are ash prior fitted per level coefficient on var 1
# element in  (log2(Y_f)+2):  2*( log2(Y_f)+1)   of G_prior   are ash prior fitted per level coefficient on var 2
class(G_prior) <- prior
}
return(G_prior)
}
G <- init_prior(Y=Y_f,X, prior="mixture_normal", v1=v1,indx_lst = indx_lst)
class(G)== "mixture_normal"
G <- init_prior(Y=Y_f,X, prior="mixture_normal_per_scale", v1=v1,indx_lst = indx_lst)
temp <- get_Bhat_Shat(Y,X,v1 )   ## Speed Gain would be good to call directly get_Bhat_Shat in the ash function
G_prior  <-  lapply(1: log2(dim(Y)[2]) ,
FUN= fit_ash_level, Bhat=temp$Bhat, temp$Shat, indx_lst )
init_prior <- function(Y,X, prior,v1 , indx_lst )
{
if( prior == "mixture_normal")
{
temp <- get_Bhat_Shat(Y,X,v1 )   ## Speed Gain would be good to call directly get_Bhat_Shat in the ash function
G_prior <- list()
G_prior[[1]]  <-  ash(c(temp$Bhat), c(temp$Shat),mixcompdist ="normal")
class(G_prior) <- "mixture_normal"
}
if( prior == "mixture_normal_per_scale")
{
temp <- get_Bhat_Shat(Y,X,v1 )   ## Speed Gain would be good to call directly get_Bhat_Shat in the ash function
G_prior  <-  lapply(1: log2(dim(Y)[2]) ,
FUN= function(s) fit_ash_level(  Bhat=temp$Bhat, temp$Shat,s=s, indx_lst ) )
#first log2(Y_f)+1 element of G_prior   are ash prior fitted per level coefficient on var 1
# element in  (log2(Y_f)+2):  2*( log2(Y_f)+1)   of G_prior   are ash prior fitted per level coefficient on var 2
class(G_prior) <- prior
}
return(G_prior)
}
G <- init_prior(Y=Y_f,X, prior="mixture_normal_per_scale", v1=v1,indx_lst = indx_lst)
class(G)== "mixture_normal_per_scale"
G
library(testthat)
set.seed(2)
f1 <- simu_IBSS_per_level(lev_res=9, alpha=1, prop_decay =1.5)
plot(f1$sim_func, type="l", ylab="y")
N=500
P=10
set.seed(23)
G = matrix(sample(c(0, 1,2), size=N*P, replace=T), nrow=N, ncol=P) #Genotype
beta0       <- 0
beta1       <- 1
pos1 <- 5
noisy.data  <- list()
rsnr=0.5
for ( i in 1:N)
{
f1_obs <- f1$sim_func
noisy.data [[i]] <-   beta1*G[i,pos1]*f1_obs +  rnorm(length(f1$sim_func), sd=  (1/  rsnr ) *sd(f1$sim_func))
}
noisy.data <- do.call(rbind, noisy.data)
Y <- noisy.data
X <- G
W <- DWT2(Y)
update_D <- W
Y_f <- cbind( W$D,W$C) #Using a column like phenotype
update_Y <-Y_f
v1 <- rep(1, dim(X)[2])
indx_lst <- gen_wavelet_indx(9)
G <- init_prior(Y=Y_f,X, prior="mixture_normal", v1=v1,indx_lst = indx_lst)
class(G)== "mixture_normal"
G <- init_prior(Y=Y_f,X, prior="mixture_normal_per_scale", v1=v1,indx_lst = indx_lst)
class(G)== "mixture_normal_per_scale"
test_that("Class of the prior is", {
expect_equal(class(
init_prior(Y=Y_f,
X=X,
prior="mixture_normal",
v1=v1,
indx_lst = indx_lst)
),
"mixture_normal"
)
expect_equal(class(
init_prior(Y=Y_f,
X=X,
prior="mixture_normal_per_scale",
v1=v1,
indx_lst = indx_lst)
),
"mixture_normal_per_scale"
)
})
get_log_BF.mxiture_normal <- function( G_prior  ,Bhat,Shat, indx_lst )
{
get_t_col_post <- function(t ){
m <- (G_prior [[1]]   )
m$fitted_g$pi
tt <-  rep(0, length(Shat[t,  ]))
pi_k <- m$fitted_g$pi
sd_k <- m$fitted_g$sd
for( k in 1:length( m$fitted_g$pi))  ## Speed Gain #could potential skip the one that are exactly 0
{
tt <- tt+ pi_k[k]*dnorm(Bhat[t,  ], sd= sqrt(sd_k[k]^2 +Shat[t,  ]^2))
}
out <- sum (log(tt) -   log(dnorm(  Bhat[t,  ],sd= Shat[t,  ])))
return( out )
}
out <- lapply( 1:(dim(X)[2]),
FUN= get_t_col_post)
return(do.call(c, out))
}
get_logBF(G,Bhat,Shat)
get_log_BF(G,Bhat,Shat)
get_log_BF.mixture_normal_per_scale <- function( G_prior ,Bhat,Shat, indx_lst )
{
get_t_col_post <- function(t ){
get_t_s_post <- function(s){
m <- G_prior  [[(t-1)*(log2(dim(Bhat)[2] )+1)+s]] ## Speed Gain #could potential skip the one that are exactly 0
data <-  set_data(Bhat[t,indx_lst[[s]] ],
Shat[t, indx_lst[[s]] ]
)
return(calc_logLR (get_fitted_g(m),data))
}
return(sum(unlist(lapply(1:(log2(dim(Bhat)[2] )+1 ),#important to maintain the ordering of the wavethresh package !!!!
get_t_s_post ))))
}
out <- lapply( 1:(dim(Bhat)[1]),
FUN= get_t_col_post)
return(do.call(c, out))
}
get_log_BF.mixture_normal <- function( G_prior  ,Bhat,Shat, indx_lst )
{
get_t_col_post <- function(t ){
m <- (G_prior [[1]]   )
m$fitted_g$pi
tt <-  rep(0, length(Shat[t,  ]))
pi_k <- m$fitted_g$pi
sd_k <- m$fitted_g$sd
for( k in 1:length( m$fitted_g$pi))  ## Speed Gain #could potential skip the one that are exactly 0
{
tt <- tt+ pi_k[k]*dnorm(Bhat[t,  ], sd= sqrt(sd_k[k]^2 +Shat[t,  ]^2))
}
out <- sum (log(tt) -   log(dnorm(  Bhat[t,  ],sd= Shat[t,  ])))
return( out )
}
out <- lapply( 1:(dim(X)[2]),
FUN= get_t_col_post)
return(do.call(c, out))
}
get_log_BF(G,Bhat,Shat)
