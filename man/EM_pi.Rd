% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/computational_functions.R
\name{EM_pi}
\alias{EM_pi}
\title{EM algorithm to select mixture weight in a  Empirical Bayes way}
\usage{
EM_pi(
  G_prior,
  Bhat,
  Shat,
  indx_lst,
  max_step = 100,
  espsilon = 1e-04,
  init_pi0_w = 1,
  control_mixsqp
)
}
\arguments{
\item{G_prior}{mixture normal prior  or mixture  normal per scale}

\item{Bhat}{matrix pxJ regression coefficient, Bhat[j,t] corresponds to regression coefficient of Y[,t] on X[,j]}

\item{Shat}{matrix pxJ standard error, Shat[j,t] corresponds to standard error of the regression coefficient of Y[,t] on X[,j]}

\item{max_step}{numeric, maximum number of EM iteration}

\item{espsilon}{numeric, tolerance EM algorithm}

\item{init_pi0_w}{starting value of weight on null compoenent in mixsqp}

\item{control_mixsqp}{list of parameter for mixsqp function see\link{\code{mixsqp}}}

\item{indx_list}{list generated by \code{\link{gen_wavelet_indx}} for the given level of resolution, used only with class mixture_normal_per_scale}
}
\value{
\item{tpi_k}{ fitted mixture proportion}
\item{lBF}{ log Bayes Factor}
}
\description{
Select the mixture wieght by maximizing the marginal likelihood
}
