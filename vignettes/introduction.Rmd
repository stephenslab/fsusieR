---
title: "Introduction"
author: "William R.P. Denault"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{introduction}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# fSuSiE^[this vignette is based on the original SuSiE vignette by [Gao Wang](https://stephenslab.github.io/susieR/articles/finemapping.html) ]
 In this package we implement a  Bayesian variable selection method called the "Functional Sum of Single Effects" ({\em fSuSiE}) model that extends the {\em SuSiE} model of Wang et al.  to functional phenotypes that can span over large genomic regions. The methods implemented here are particularly well-suited to settings where some of the X variables are highly correlated, and the true effects are highly sparse (e.g. <20 non-zero effects in the vector b). One example of this is genetic fine-mapping of complex molecular traitsthat vary along the genome; such as molecular measurement from sequencing assays (ChIP-seq, ATAC-seq ), as well as DNA methylation. However, the methods should also be useful more generally (e.g. detecting change in time series).

###Model Description 
fSuSiE fits the following linear regression $\bm{Y} = \bm{XB} + \bm{E}$, where $\bm{Y}$ is a N x T matrix containing the observed curves, $\bm{X}$ is the N × p matrix of  single nucleotide polymorphisms (SNP) in the region to be fine-mapped. $\bm{B}$ is a p × T matrix whose element $b_{jt}$ is the effect of SNP $j$ on the trait at location t, and $\bm{E}$ is a matrix of error terms which initially we consider to be normally-distributed with variance $\sigma^2$. Analogous to regular fine-mapping, the matrix $\bm{B}$ is expected to be sparse, i.e., most rows will be zero. Non-zero rows correspond to SNPs that do affect the trait. The goal is to identify the non-zero rows of  $\bm{B}$. We extended  {\em SuSiE} to functional traits by writing $\bm{B}= \sum_l^M \bm{B}^{(l)}$, where each "single-effect" matrix $\bm{B}^{(l)}$ has only one non-zero row, corresponding to a single causal SNP. We devised a fast variational inference procedure~\cite{blei_variational_2017} for fitting this model by first projecting the data in the wavelet space and then using an adaptation of the efficient iterative Bayesian stepwise selection (IBSS) approach proposed by Wang and colleagues .


The output of the fitting procedure is a number of “Credible Sets” (CSs), which are each designed to have high probability to contain a variable with non-zero effect, while at the same time being as small as possible. You can think of the CSs as being a set of “highly correlated” variables that are each associated with the response: you can be confident that one of the variables has a non-zero coefficient, but they are too correlated to be sure which one.

The package is developed by William R.P. Denault from the Stephens Lab at the University of Chicago.

Please post issues to ask questions, get our support or provide us feedback; please send pull requests if you have helped fixing bugs or making improvements to the source code.


### Using fSuSiE

#### the data
This vignette demonstrates fsusieR in the context of genetic fine-mapping. We use simulated data of expression level of a gene (y) in N≈600 individuals. We want to identify with the genotype matrix X  (P=1000)

  the genetic variables that causes changes in expression level.

The simulated data set is simulated to have exactly 2 non-zero effects.

Here we simulate the effect 
```{r}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
library(susiF.alpha)
library(ashr)
library(susieR)
set.seed(1)
data(N3finemapping)
attach(N3finemapping)

rsnr <- 0.5 #expected root signal noise ratio

pos1 <- 1   #Position of the causal covariate for effect 1
pos2 <- 500   #Position of the causal covariate for effect 1
lev_res <- 7#length of the molecular phenotype (2^lev_res)
f1 <-  simu_IBSS_per_level(lev_res )$sim_func#first effect
f2 <- simu_IBSS_per_level(lev_res )$sim_func #second effect

plot( f1, type ="l", ylab="effect", col="blue")
abline(a=0,b=0)
lines(f2, type="l", col="green")
legend(x=100,
       y=3,
       lty = rep(1,3),
      legend= c("effect 1", "effect 2" ),
       col=c("black","blue","yellow"))

```


Here we generate the observed curves (effect +noise)



```{r}

noisy.data  <- list()

for ( i in 1:nrow(X))
{
  f1_obs <- f1
  f2_obs <- f2
  noise <- rnorm(length(f1), sd=  (1/  rsnr ) * var(f1))
  noisy.data [[i]] <-  X[i,pos1]*f1_obs +X[i,pos2]*f2_obs + noise

}
noisy.data <- do.call(rbind, noisy.data)
plot( noisy.data[1,], type = "l", col=(X[1, pos1]*3+1),
     main="Observed curves \n colored by the causal effect", ylim= c(-40,40), xlab="")
for ( i in 2:nrow(X))
{
  lines( noisy.data[i,], type = "l", col=(X[i, pos1]*3+1))

}
legend(x=0.3,
       y=-10,
       lty = rep(1,3),
       legend= c("0", "1","2"),
       col=c("black","blue","yellow"))

Y <- noisy.data


```

#### Output and interpretation

So basically running fSuSiE requires: a Y matrix in which each line correspond to a individual profile. X the genotype matrix in
which each line represent the individual genotype and the column the different SNPs.



```{r}
 out <- susiF(Y,X,L=10 , prior = 'mixture_normal_per_scale')
```


the easiest way to visualize the result is to use the \code{plot_susiF} function

```{r}
 
 plot_susiF(out)
 

```

 You can also access the information directly in the output of susiF in the fitted_func part of the output. See below  as follow
 
 
```{r}
 par(mfrow=c(1,2))
 
 plot( f1, type="l", main="Estimated effect 1", xlab="")
 lines(unlist(out$fitted_func[[1]]),col='blue' )
 abline(a=0,b=0)
 legend(x= 35,
        y=3,
        lty= rep(1,2),
        legend = c("effect 1"," fSuSiE est "),
        col=c("black","blue" )
 )
 plot( f2, type="l", main="Estimated effect 2", xlab="")
 lines(unlist(out$fitted_func[[2]]),col='green' )
 abline(a=0,b=0)
 legend(x= 20,
        y=-1.5,
        lty= rep(1,2),
        legend = c("effect 2"," fSuSiE est "),
        col=c("black","green" )
 )
 
 par(mfrow=c(1,1))
```
 
###Credible sets

Credible sets

By default, we output 95% credible set:

###Posterior inclusion probabilities

Previously we’ve determined that summing over 3 single effect regression models is approperate for our application. Here we summarize the variable selection results by posterior inclusion probability (PIP):

 The true causal variables are colored red. The 95% CS identified are circled in different colors. Of interest is the cluster around position 400. The true signal is 403 but apparently it does not have the highest PIP. To compare ranking of PIP and original z-score in that CS:
 
 
 
 #### A note on the different available priors

Notice that by default SuSiE estimates prior effect size from data. For fine-mapping applications, however, we sometimes have knowledge of SuSiE prior effect size since it is parameterized as percentage of variance explained (PVE) by a non-zero effect, which, in the context of fine-mapping, is related to per-SNP heritability. It is possible to use scaled_prior_variance to specify this PVE and explicitly set estimate_prior_variance=FALSE to fix the prior effect to given value.

In this data-set, SuSiE is robust to choice of priors. Here we set PVE to 0.2, and compare with previous results:
